# TLDR Newsletter Summary: 2025-07-15

## TLDR2025-07-15

### Fast
 Track Impact with Glean's Work AI (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.glean.com%2Fwebinars%2Ffast-track-to-impact%2F%3Futm_source=3rd-party%26utm_medium=email%26utm_campaign=fast-track-to-impact-glean-success%26utm_partner=tldr-flagship/2/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/ijwm4KLx92BDU0bG4vnuyKy1ch-eYIJWyLXLuoXh0xU=413
**TLDR Summary:** Ready to break free from slow, drawn-out AI pilot rollouts? Glean transforms productivity from day one, helping you break through information silos and deliver the business outcomes your team cares about right away. Join Glean's Fast Track to Impact live webinar on July 17 to discover how teams at Reddit, Rivian, and Booking.com are reclaiming 100+ hours of productivity per person each year with Glean's unified search and GenAI capabilities. Register now → Can't wait to see what immediate impact looks like for your organization? Book a personalized walkthrough to see Glean in action and start transforming productivity across your company. Book a walkthrough →
**Full Article Content:**
Drive rapid results across your organization by strategically deploying Glean’s core features from day one. This session equips IT leaders, admins, and decision-makers with concrete information about how Glean can drive valuable results for every employee through the power of AI.



Discover how Glean’s search and GenAI capabilities can unlock the power of your company’s knowledge across applications. See how our advanced RAG capabilities, powered by best-in-class enterprise search, knowledge graphs, and permissions-enforced, empower enterprises. Position your organization to fuel collaboration, innovation, and growth from day one with Glean.

What You’ll Learn

---

## Big Tech & Startups

### Meta's
 New Superintelligence Lab Is Discussing Major A.I. Strategy Changes (3 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FIiyBZK/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/yRjqDk0p07mRoQ-OatszHhVoy8mqHLQoJ4BGmeh94PU=413
**TLDR Summary:** A small group of members in Meta's newly formed superintelligence lab last week discussed the possibility of abandoning the company's most powerful open source AI model, Behemoth, in favor of developing a closed model. Meta has chosen to open source its AI models for years, with executives arguing that it is better for the technology to be public to accelerate AI development and make the technology more accessible to developers. A move to a closed AI model would be a philosophical change as much as a technical one. Meta has been delaying the release of its Behemoth model due to its poor internal performance.
**Full Article Content:**
[Scraping failed for this URL. Error: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html?unlocked_article_code=1.Wk8.OcqB.PxMXKAOg8pHX&smid=url-share&utm_source=tldrnewsletter on URL https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FIiyBZK/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/yRjqDk0p07mRoQ-OatszHhVoy8mqHLQoJ4BGmeh94PU=413]

---

### Meta's
 New Superintelligence Lab Is Discussing Major A.I. Strategy Changes (3 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FIiyBZK/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/yRjqDk0p07mRoQ-OatszHhVoy8mqHLQoJ4BGmeh94PU=413
**TLDR Summary:** A small group of members in Meta's newly formed superintelligence lab last week discussed the possibility of abandoning the company's most powerful open source AI model, Behemoth, in favor of developing a closed model. Meta has chosen to open source its AI models for years, with executives arguing that it is better for the technology to be public to accelerate AI development and make the technology more accessible to developers. A move to a closed AI model would be a philosophical change as much as a technical one. Meta has been delaying the release of its Behemoth model due to its poor internal performance.
**Full Article Content:**
[Scraping failed for this URL. Error: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html?unlocked_article_code=1.Wk8.OcqB.PxMXKAOg8pHX&smid=url-share&utm_source=tldrnewsletter on URL https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FIiyBZK/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/yRjqDk0p07mRoQ-OatszHhVoy8mqHLQoJ4BGmeh94PU=413]

---

### Google
 exec: ‘We're going to be combining ChromeOS and Android' (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.theverge.com%2Fnews%2F706558%2Fgoogle-android-chromeos-combining-sameer-samat%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/Q-YXo4r-R6_o-tXvXAJt23GCrCYjfGTG6sxkHG6oRYA=413
**TLDR Summary:** Google plans to combine Android with ChromeOS. Chromebooks can already run many Android apps, and Android has been moving closer to ChromeOS with new features like desktop mode, resizable windows, and improved support for external displays. Bringing the two operating systems together makes sense as it will speed up feature development and improve functionality on tablets.
**Full Article Content:**
Google’s head of Android has said that the company plans to combine its mobile operating system with ChromeOS, the software that currently runs across Google’s Chromebook laptops.

Sameer Samat, president of Google’s Android ecosystem, told TechRadar that “we’re going to be combining Chrome OS and Android into a single platform.” Samat, who’s responsible for Android’s implementation across mobile, wearables, XR, TV, and auto, added that he’s “interested in how people are using their laptops these days,” suggesting he may be adding a new string to his bow.

The comment is the closest thing yet to official confirmation of a change that’s been rumored for months. In November 2024 Android Authority reported that Google is “migrating ChromeOS over to Android,” with the aim of competing with the iPad. That process may have already begun, with Google itself announcing last June that ChromeOS will now be “developed on large portions of the Android stack.” Chromebooks can already run many Android apps.

Meanwhile Android is getting a little closer to ChromeOS this year with new features including a desktop mode, resizable windows, and improved support for external displays.

Google bringing its two operating systems under one roof makes a lot of sense on paper, allowing it to speed up feature development and work on improving functionality on tablets, where both its current OSes lag behind Apple’s iPadOS. Then again, that’s been true for a while — a merger of the two platforms was reported ten years ago in 2015, and The Verge wrote that it “makes perfect sense to bring them together” two years before that. This is a change that’s been a long time coming, but that means it might be a long time still.

---

## Science & Futuristic Technology

### COVID-19
 vaccine technology adapted to develop first mRNA defense against antibiotic-resistant bacteria (4 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmedicalxpress.com%2Fnews%2F2025-07-covid-vaccine-technology-mrna-defense.html%23google_vignette%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/kVdL1xRx9jNS1tuncRgL-evEPe35E5pUG_G20BDCVsc=413
**TLDR Summary:** Israeli researchers have created an mRNA-based vaccine against Yersinia pestis, the bacterium that causes bubonic plague. The researchers hope the technology can be used to combat other lethal bacteria as well. When tested on animal models, the vaccine achieved 100% protection against pneumonic plague. The success of the study paves the way for a whole world of mRNA-based vaccines against other deadly bacteria.
**Full Article Content:**
This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Design and synthesis of mRNA-LNPs used in the study, physicochemical characteristics and in vitro expression. Credit: Advanced Science (2025). DOI: 10.1002/advs.202501286

Researchers from Tel Aviv University and the Israel Institute for Biological Research in Ness Ziona have used the platform developed for COVID-19 vaccines to create the world's first mRNA-based vaccine against a deadly, antibiotic-resistant bacterium.

In this study, the researchers tested the vaccine's resistance to the virulent pathogen that causes the disease and were able to demonstrate 100% protection against infection in animal models. The researchers now hope that this technology can be used to combat other lethal bacteria as well.

The study was led by Tel Aviv University's Vice President for Research and Development Prof. Dan Peer, a global pioneer in mRNA drug development and director of the Laboratory of Precision NanoMedicine at the Shmunis School of Biomedicine and Cancer Research. He worked alongside researchers from the Israel Institute for Biological Research—Dr. Uri Elia, Dr. Yinon Levy, Dr. Emmy Mamroud, and Dr. Ofer Cohen—as well as members of his own laboratory team: Dr. Edo Kon, Dr. Inbal Hazan-Halevy, and doctoral student Shani Benarroch.

The study was featured on the cover of the journal Advanced Science.

The vaccine developed by the team from the Institute for Biological Research and Tel Aviv University is an mRNA-based vaccine delivered via lipid nanoparticles, similar to the COVID-19 vaccine. However, mRNA vaccines are typically effective against viruses like COVID-19—not against bacteria like the plague.

Dr. Elia explains, "Viruses rely on a host cell to survive and replicate. They infect the cell with an RNA molecule (mRNA) that contains instructions for making viral proteins. The virus uses the cell as a factory to replicate itself. In an mRNA vaccine, this molecule is synthesized and encased in a lipid nanoparticle that resembles human cell membranes.

"The nanoparticle fuses with the cell, the cell produces the viral proteins, and the immune system learns to recognize and defend against the actual virus upon exposure. Bacteria, however, are a different story: they produce their own proteins and do not rely on human cells. Moreover, due to the different evolutionary paths of humans and bacteria, their proteins are very different from ours."

In 2023, the researchers developed a unique method for producing the bacterial protein within a human cell in a way that prompts the immune system to recognize it as a genuine bacterial protein and thus learn to defend against it.

The researchers from Tel Aviv University and the Institute for Biological Research proved, for the first time, that it is possible to develop an effective mRNA vaccine against bacteria. They chose Yersinia pestis, the bacterium that causes bubonic plague—a disease responsible for deadly pandemics throughout human history. In animal models, the researchers demonstrated that it is possible to effectively vaccinate against the disease with a single dose.

Prof. Peer says, "In the previous study, we developed a vaccine for a form of plague transmitted through the skin—for example, via flea bites. In the current study, we chose a much more ambitious target: pneumonic plague, which spreads from person to person and causes respiratory illness—making it particularly difficult to develop a vaccine against.

"For this reason, we used two proteins—two antigens—to create the vaccine. We tested it on several animal model strains and found that, after two vaccine doses, we achieved 100% protection against pneumonic plague: the animals infected with the plague did not get sick at all. The success of the current study paves the way for a whole world of mRNA-based vaccines against other deadly bacteria."

"The plague—a disease that killed about two-thirds of Europe's population in the Middle Ages ('The Black Death') still resurfaces occasionally today, for example in Madagascar. "So the potential for a pandemic still exists," says Dr. Elia.

"The disease is caused by a bacterium called Yersinia pestis, for which there is no approved vaccine in Western countries. This bacterium is highly contagious and extremely lethal, making it a serious threat. Moreover, this bacterium concerns us as a potential agent of bioterrorism. If one of our enemies tries to use it against us, we want to be prepared with a vaccine."

More information: Uri Elia et al, Novel Bivalent mRNA‐LNP Vaccine for Highly Effective Protection against Pneumonic Plague, Advanced Science (2025). DOI: 10.1002/advs.202501286 Journal information: Advanced Science

---

### COVID-19
 vaccine technology adapted to develop first mRNA defense against antibiotic-resistant bacteria (4 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmedicalxpress.com%2Fnews%2F2025-07-covid-vaccine-technology-mrna-defense.html%23google_vignette%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/kVdL1xRx9jNS1tuncRgL-evEPe35E5pUG_G20BDCVsc=413
**TLDR Summary:** Israeli researchers have created an mRNA-based vaccine against Yersinia pestis, the bacterium that causes bubonic plague. The researchers hope the technology can be used to combat other lethal bacteria as well. When tested on animal models, the vaccine achieved 100% protection against pneumonic plague. The success of the study paves the way for a whole world of mRNA-based vaccines against other deadly bacteria.
**Full Article Content:**
This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Design and synthesis of mRNA-LNPs used in the study, physicochemical characteristics and in vitro expression. Credit: Advanced Science (2025). DOI: 10.1002/advs.202501286

Researchers from Tel Aviv University and the Israel Institute for Biological Research in Ness Ziona have used the platform developed for COVID-19 vaccines to create the world's first mRNA-based vaccine against a deadly, antibiotic-resistant bacterium.

In this study, the researchers tested the vaccine's resistance to the virulent pathogen that causes the disease and were able to demonstrate 100% protection against infection in animal models. The researchers now hope that this technology can be used to combat other lethal bacteria as well.

The study was led by Tel Aviv University's Vice President for Research and Development Prof. Dan Peer, a global pioneer in mRNA drug development and director of the Laboratory of Precision NanoMedicine at the Shmunis School of Biomedicine and Cancer Research. He worked alongside researchers from the Israel Institute for Biological Research—Dr. Uri Elia, Dr. Yinon Levy, Dr. Emmy Mamroud, and Dr. Ofer Cohen—as well as members of his own laboratory team: Dr. Edo Kon, Dr. Inbal Hazan-Halevy, and doctoral student Shani Benarroch.

The study was featured on the cover of the journal Advanced Science.

The vaccine developed by the team from the Institute for Biological Research and Tel Aviv University is an mRNA-based vaccine delivered via lipid nanoparticles, similar to the COVID-19 vaccine. However, mRNA vaccines are typically effective against viruses like COVID-19—not against bacteria like the plague.

Dr. Elia explains, "Viruses rely on a host cell to survive and replicate. They infect the cell with an RNA molecule (mRNA) that contains instructions for making viral proteins. The virus uses the cell as a factory to replicate itself. In an mRNA vaccine, this molecule is synthesized and encased in a lipid nanoparticle that resembles human cell membranes.

"The nanoparticle fuses with the cell, the cell produces the viral proteins, and the immune system learns to recognize and defend against the actual virus upon exposure. Bacteria, however, are a different story: they produce their own proteins and do not rely on human cells. Moreover, due to the different evolutionary paths of humans and bacteria, their proteins are very different from ours."

In 2023, the researchers developed a unique method for producing the bacterial protein within a human cell in a way that prompts the immune system to recognize it as a genuine bacterial protein and thus learn to defend against it.

The researchers from Tel Aviv University and the Institute for Biological Research proved, for the first time, that it is possible to develop an effective mRNA vaccine against bacteria. They chose Yersinia pestis, the bacterium that causes bubonic plague—a disease responsible for deadly pandemics throughout human history. In animal models, the researchers demonstrated that it is possible to effectively vaccinate against the disease with a single dose.

Prof. Peer says, "In the previous study, we developed a vaccine for a form of plague transmitted through the skin—for example, via flea bites. In the current study, we chose a much more ambitious target: pneumonic plague, which spreads from person to person and causes respiratory illness—making it particularly difficult to develop a vaccine against.

"For this reason, we used two proteins—two antigens—to create the vaccine. We tested it on several animal model strains and found that, after two vaccine doses, we achieved 100% protection against pneumonic plague: the animals infected with the plague did not get sick at all. The success of the current study paves the way for a whole world of mRNA-based vaccines against other deadly bacteria."

"The plague—a disease that killed about two-thirds of Europe's population in the Middle Ages ('The Black Death') still resurfaces occasionally today, for example in Madagascar. "So the potential for a pandemic still exists," says Dr. Elia.

"The disease is caused by a bacterium called Yersinia pestis, for which there is no approved vaccine in Western countries. This bacterium is highly contagious and extremely lethal, making it a serious threat. Moreover, this bacterium concerns us as a potential agent of bioterrorism. If one of our enemies tries to use it against us, we want to be prepared with a vaccine."

More information: Uri Elia et al, Novel Bivalent mRNA‐LNP Vaccine for Highly Effective Protection against Pneumonic Plague, Advanced Science (2025). DOI: 10.1002/advs.202501286 Journal information: Advanced Science

---

### DARPA
 Sets New Record for Wireless Power Beaming (4 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fspectrum.ieee.org%2Fdarpa-optical-wireless-power%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/H3xYmTFmZ38aSOze767KX6z01sDkY5Q3XE9hwiJAHVU=413
**TLDR Summary:** The United States' Defense Advanced Research Projects Agency (DARPA) recently transferred over 800 watts of power over about 30 seconds with a laser beam across 8.6 kilometers. The estimated power efficiency was around 20%. The team used commercial ready-to-use solar cells placed within a receiver to turn the laser beam into electricity. Laser technologies are more suitable than infrared for building an airborne power relay network due to their high precision, long-range reach, and lighter and smaller equipment required to work.
**Full Article Content:**
The United States’ Defense Advanced Research Projects Agency (DARPA) recently achieved a new record in transmitting energy over distance. In tests performed in New Mexico, the Persistent Optical Wireless Energy Relay (POWER) program team recorded over 800 watts of power delivered for about 30 seconds with a laser beam crossing 8.6 kilometers.

The greatest distance records previously recorded were 230 watts of average power for 25 seconds at 1.7 km, and an undisclosed amount of power at 3.7 km.

The feat wraps up phase one of a three-phase project.

RELATED: Practical Power Beaming Gets Real



The estimated receiver efficiency, says POWER team leader Paul Jaffe, is around 20 percent. In other studies, some industrial lasers have recorded a wall-plug efficiency higher than 50 percent. Higher receiver efficiencies are achievable, especially with the use of photovoltaic cells optimized for particular wavelengths—whose production is usually costly and time-consuming.

This was not the case here, Jaffe says. The team used commercial ready-to-use solar cells placed within a receiver. As it takes in the laser beam, the receiver reflects the infrared radiation from a conical mirror onto the photovoltaic cells—which, in turn, turns that beam into usable electricity. At this stage, the goal, Jaffe says, was not efficiency, but speed. “There’s a number of design decisions that were made in the interest of building something quickly, not efficiently,” he says.

And by quickly, they mean a timeline of three months between planning and execution, says Raymond Hoheisel, founder of Teravec Technologies, the company that developed the receiver. “The breakthrough was to prove this technology can be affordable,” he says.

While DARPA did not disclose what the total transmission power was, results show the ensuing output energy was about 800 W. “And we managed to succeed in tests with the receiver running over more extended periods of time [longer than the reported 30 seconds],” Hoheisel says.

Many long-distance power-beaming projects focus on radio (or microwave) frequencies—which means using large transmitters to realize a gain in distance traveled. A process called beamforming is essential for such power transmission to work.

Paul Mitcheson, a professor in electrical energy conversion in the Imperial College London’s Control and Power Research Group, describes it like this: In broadcast television or radio, the objective is to propagate the signal as widely as possible so that many people can tune in to a given channel. “That’s exactly what you don’t want to do when you’re beaming power,” he says. In this case, the goal is to beam the signal straight into a receiver with as little loss as possible. “So we need a different structure: The antenna needs to have what we call high gain so that it transmits in one specific direction, with a high degree of directionality.” This is the beamforming process that allows our phones to send a signal to a base station instead of broadcasting it everywhere, Mitcheson adds.

But still, there are signal losses. In different ways, infrared laser (or optical) beams have an edge over radio frequencies, says Eric Yeatman, vice-principal and head of the College of Science and Engineering at the University of Glasgow. “Compared to radio, laser is much more focusable—you can create a narrow beam [almost] without any spreading [in ideal conditions],” he says.

But as optical frequencies still scatter with fog and clouds, microwaves are generally superior for atmospheric transmission, Jaffe says. On the other hand, lasers do not require the large antennas that radio does. In a previous test he was part of at the Naval Research Laboratory, Jaffe says they required a 5-meter transmitter and a 2-meter receiver to send 1.6 kW across 1 km via microwave frequencies.

Radio wave wavelengths are much longer than infrared, so beamforming is more difficult. “What you want is a sort of column of waves. [In any given transmission], the output diameter needs to be much larger than the wavelength, and this is what determines whether you can focus something or not,” Yeatman says. Infrared’s shorter wavelengths mean creating a focused beam is much easier.

Because of its high precision, long-range reach, and lighter and smaller equipment required to work, laser technologies are more suitable for building an airborne power relay network. “If it doesn’t work with optical, it doesn’t work at all [for DARPA’s goal],” Jaffe says.

“Though the idea of transferring power by laser isn’t new, what they did was an impressive achievement,” says Yeatman.

Paul Jaffe (in orange) stands with the POWER Receiver Array Demo team around the receiver after achieving a new record for wireless power beaming at the High Energy Laser Systems Test Facility in New Mexico. U.S. Army White Sands Missile Range

The record, Jaffe says, came as a surprise, as it was not the team’s objective. And it’s not the project’s only surprise since it began in 2023. The use of diffractive optics was another of them. People usually think of a mirror or a lens when it comes to redirecting laser beams, Jaffe says. “But one of the things we found is that diffractive optics may be very well suited for this, particularly because they are good at efficiently handling monochromatic wavelengths of light. This was something we didn’t know at the outset and that revealed itself as we moved forward,” he says.

Additively manufactured optics with an integrated cooling system were also something that was not on the script when the project started out. The fact that they managed to do it, Jaffe says, “revealed new and intriguing ways to tackle some of the problems that are very likely to have applications far beyond what we’re doing for POWER.”

---

## Programming, Design & Data Science

### Delve
 generated $1M in pipeline from TLDR newsletter ads (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2Fcase-studies%2Fdelve-drives-1m-in-attributed-pipeline-52x-roi-through-tldr-ads%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=secondary07152025/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/97zX3-Y6hVMifY15zXPteEt9rK26dNwmFsIfqq6Lyx8=413
**TLDR Summary:** Delve ran 4 ads across 2 TLDR newsletters and brought in 66 leads, with a meaningful chunk from enterprise. The result: $1M in attributed pipeline and a 52x ROI. This case study breaks down their strategy, results, and example ads. Read the Delve case study.
**Full Article Content:**
“Newsletters presented themselves as a really great way to reach our target audience—founders. Founders are always looking to be sold to where they enjoy going, which tend to be places where they can be educated. They want to stay up to date on the best new tech, and they’re usually pretty willing to adopt new solutions if they make sense for them and there’s some social proof.”

---

### Delve
 generated $1M in pipeline from TLDR newsletter ads (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2Fcase-studies%2Fdelve-drives-1m-in-attributed-pipeline-52x-roi-through-tldr-ads%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=secondary07152025/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/97zX3-Y6hVMifY15zXPteEt9rK26dNwmFsIfqq6Lyx8=413
**TLDR Summary:** Delve ran 4 ads across 2 TLDR newsletters and brought in 66 leads, with a meaningful chunk from enterprise. The result: $1M in attributed pipeline and a 52x ROI. This case study breaks down their strategy, results, and example ads. Read the Delve case study.
**Full Article Content:**
“Newsletters presented themselves as a really great way to reach our target audience—founders. Founders are always looking to be sold to where they enjoy going, which tend to be places where they can be educated. They want to stay up to date on the best new tech, and they’re usually pretty willing to adopt new solutions if they make sense for them and there’s some social proof.”

---

### AWS
 previews Kiro IDE for developers who are over vibe coding (3 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.theregister.com%2F2025%2F07%2F14%2Faws_kiro_agentic_ide%2F%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/dGOWAbcyHxB4v-n366yzMJ-HlBoCvQn9klcU04Y2jhc=413
**TLDR Summary:** AWS has introduced a new agentic IDE called Kiro that apparently avoids the pitfalls of vibe coding. It is built around a conversational interface that offers developers the chance to explain what they are trying to build. Kiro then uses generative AI to produce its response, which initially takes the form of a spec, not actual code. Kiro can handle multiple specs created by different teams that all work on different aspects of a project. It can use plugins written for VS Code and Open VSX.
**Full Article Content:**
Amazon Web Services has created what it's calling an "agentic IDE" that it claims avoids the pitfalls of vibe coding.

With the advent of generative AI, developers have experimented with using LLMs to rapidly generate and debug code in a process that's come to be known as vibe coding. But the code is often of low quality and requires more time to debug and modify than it ultimately saves. A recent study found that in some cases developers believe these tools are saving them time when it's in fact precisely the opposite.

AWS's tool is called "Kiro" and, as Deepak Singh, veep for developer agents and experiences, explained to The Register, it's built around a conversational interface that offers developers the chance to explain what they're trying to build. Kiro uses generative AI to produce its response, which initially takes the form of a spec, not actual code.

Singh said the specs are "just markdown or text or pseudocode and are written like user stories."

Nikhil Swaminathan, AWS senior manager for agentic AI developer tools, explained that each user story "includes EARS (Easy Approach to Requirements Syntax) notation acceptance criteria covering edge cases developers typically handle when building from basic user stories."

Kiro's output also includes a list of services and actual code that's pushed to Git. Kiro can also handle multiple specs created by different teams that all work on different aspects of a project.

Singh suggested that working with specs matters because when developers use coding assistants such as AWS's own Q, code quality is low and few bother to keep track of which prompts produce good results.

Spec produced by AWS agentic IDE Kiro – click to enlarge

AWS believes Kiro delivers code that's closer to production-ready, in an environment that's better suited to finishing a project and then maintaining it.

To that latter end, Kiro offers event-driven automations called "hooks." Singh suggested Kiro users could create a hook that automatically reviews and optimizes code every time a developer adds code to a repository.

AWS built Kiro on the open source Code OSS editor and can use plugins written for VS Code and Open VSX.

Unusually for AWS, the product is a desktop client, but users can choose which cloud-hosted models it uses to generate specs and code. It's currently in preview, but AWS plans to charge $19.99 a month with a to-be-determined number of calls to LLMs.

Singh said that despite having created Kiro and positioning it as an IDE for the agentic age, AWS still sees a role for coding assistants, and vibe coding as a way for developers to tinker and experiment. ®

---

### How
 does a screen work? (24 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.makingsoftware.com%2Fchapters%2Fhow-a-screen-works%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/kYb9Dw4q6yzJkpxRCibPnLtI1jCmcCK0A4PNUZtE9x8=413
**TLDR Summary:** Modern computing isn't possible without digital displays. The technology is underappreciated because most people have no idea how the technology works. This article covers the history of digital displays, how different types of displays work, what pixels are and why we use them, and much more. Understanding how a screen works unlocks a lot of understanding of how color works on digital displays, rasterization, GPUs, and shaders.
**Full Article Content:**
2983 words | Dan Hollick

How does a screen work?

From electron guns to tiny electric crystals - digital displays have always been the unsung hero of computing.

╌╌╌╌

---

### Meta
 CEO Zuckerberg says first AI data supercluster will come online in 2026 (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.cnbc.com%2F2025%2F07%2F14%2Fmeta-zuckerberg-ai.html%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/MBmL3Oe3oUd9SXq59_ysFH5iIOVoDicFNLDIvEqVSHo=413
**TLDR Summary:** Meta plans to invest hundreds of billions of dollars into artificial intelligence compute infrastructure. It aims to bring its first supercluster online next year. Meta has been on a multibillion-dollar AI hiring spree in recent weeks. CEO Mark Zuckerberg reportedly grew frustrated with Meta's progress in AI, so he is revamping the company's approach to better compete with rivals like OpenAI and Google.
**Full Article Content:**
Meta CEO Mark Zuckerberg on Monday said he plans to invest "hundreds of billions of dollars" into artificial intelligence compute infrastructure, and that Meta plans to bring its first supercluster online next year.

A supercluster is a large, complex computing network that's designed to train advanced AI models and handle their workloads.

"Meta Superintelligence Labs will have industry-leading levels of compute and by far the greatest compute per researcher," Zuckerberg wrote in a Facebook post on Monday. "I'm looking forward to working with the top researchers to advance the frontier!"

Zuckerberg said Meta's first supercluster is called Prometheus, and that the company is building several other multi-gigawatt clusters. One cluster, called Hyperion, will be able to scale up to five gigawatts over several years, he said.

---

### Meta
 CEO Zuckerberg says first AI data supercluster will come online in 2026 (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.cnbc.com%2F2025%2F07%2F14%2Fmeta-zuckerberg-ai.html%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/MBmL3Oe3oUd9SXq59_ysFH5iIOVoDicFNLDIvEqVSHo=413
**TLDR Summary:** Meta plans to invest hundreds of billions of dollars into artificial intelligence compute infrastructure. It aims to bring its first supercluster online next year. Meta has been on a multibillion-dollar AI hiring spree in recent weeks. CEO Mark Zuckerberg reportedly grew frustrated with Meta's progress in AI, so he is revamping the company's approach to better compete with rivals like OpenAI and Google.
**Full Article Content:**
Meta CEO Mark Zuckerberg on Monday said he plans to invest "hundreds of billions of dollars" into artificial intelligence compute infrastructure, and that Meta plans to bring its first supercluster online next year.

A supercluster is a large, complex computing network that's designed to train advanced AI models and handle their workloads.

"Meta Superintelligence Labs will have industry-leading levels of compute and by far the greatest compute per researcher," Zuckerberg wrote in a Facebook post on Monday. "I'm looking forward to working with the top researchers to advance the frontier!"

Zuckerberg said Meta's first supercluster is called Prometheus, and that the company is building several other multi-gigawatt clusters. One cluster, called Hyperion, will be able to scale up to five gigawatts over several years, he said.

---

### TikTok
 owner ByteDance is reportedly building its own mixed reality goggles (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.engadget.com%2Far-vr%2Ftiktok-owner-bytedance-is-reportedly-building-its-own-mixed-reality-goggles-212541450.html%3Fguccounter=1%26guce_referrer=aHR0cHM6Ly93d3cudGVjaG1lbWUuY29tLw%26guce_referrer_sig=AQAAAA9S6U537X3bJL1oh6jZWXy_SXexI4H3pcZup8JZ4Y02vCLLaAsViAozbV8YfDKWutm--dNRs71xxbovv7Aa3v9vldypuR72EYvybA07hI3Z8dAkWh5QM5CkUUi1af7TLKZNHJx85olITwqTJGv350SRmQxPFlGrQ5xo-p4PcPPP%26utm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/4GPPlg_7cYCYMr0qFmYq_M257dMxl3nCjmoGxG4qD3A=413
**TLDR Summary:** ByteDance is reportedly working on mixed reality goggles designed to layer digital objects over users' view of the real world to compete directly with Meta's upcoming mixed reality products. They will be built by ByteDance's Pico, the creators of the Pico 4 VR headset. Pico will keep the device lightweight by offloading most of the computing work to a puck connected to the goggles over a wire. Current Pico headsets aren't sold in the US, and ByteDance may face pushback over a US release due to its ownership of TikTok.
**Full Article Content:**
ByteDance, the parent company of TikTok, is reportedly working on mixed reality goggles, The Information reports. The in-development device is designed to layer digital objects over your view of the real world, and is supposed to compete directly with Meta's upcoming mixed reality products.

The goggles are being built by ByteDance's virtual reality startup Pico, the creators of the Pico 4 VR headset. Pico's past products have attempted to match Meta's Quest headsets in terms of features, but these new goggles apparently represent a different approach (albeit one still positioned as an alternative to Meta). Rather than a bulky headset, the goggles are supposed to be small and light, about the size of the Bigscreen Beyond VR headset, which weighs 0.28 pounds. Pico is keeping the device lightweight by offloading most of the computing work to a puck that's connected to the goggles over a wire. Meta's prototype Orion AR glasses used a wireless puck for a similar weight-saving purpose when the company demoed them in November 2024.

Pico is also reportedly working on building "specialized chips for the device that will process data from its sensors to minimize the lag or latency between what a user sees in AR and their physical movements," The Information writes.

ADVERTISEMENT Advertisement

Plenty of the details are still up in the air, but the report notes that the ByteDance / Pico goggles should be very similar to Meta's next mixed reality device. Following the release of the Quest 3S, Meta reportedly postponed work on the Quest 4 in favor of developing lightweight mixed reality goggles, according to UploadVR. The company has been publicly pushing AI wearables like the newly introduced Oakley Meta HSTN glasses, and it seems like its next Quest device will be closer to smart glasses than a VR headset with controllers.

It's not known when ByteDance's goggles will actually be released or where they'll be sold. Current Pico headsets aren't sold in the US, and given the concern over ByteDance's ownership of TikTok, it seems unlikely the company would be able to sell a mixed reality device without pushback.

---

## Quick Links

### Craving
 more AI in your inbox? (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftldr.tech%2Fai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=quicklinks07152025/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/l8h76TShc40E93S_UUHjupS6E6ZXHgBYB21zBYw7kRU=413
**TLDR Summary:** TLDR AI is your daily fix of LLMs, GenAI, and deep learning goodness. Same TLDR format. Still free. Subscribe now.
**Full Article Content:**
🧠

TLDR AI

Get smarter in under 5 minutes.

The most important AI, ML, and data science news in a free daily email.

Sign Up

No spam. Unsubscribe at any time in one click.

---

### Craving
 more AI in your inbox? (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftldr.tech%2Fai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=quicklinks07152025/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/l8h76TShc40E93S_UUHjupS6E6ZXHgBYB21zBYw7kRU=413
**TLDR Summary:** TLDR AI is your daily fix of LLMs, GenAI, and deep learning goodness. Same TLDR format. Still free. Subscribe now.
**Full Article Content:**
🧠

TLDR AI

Get smarter in under 5 minutes.

The most important AI, ML, and data science news in a free daily email.

Sign Up

No spam. Unsubscribe at any time in one click.

---

### First
 look at Gemini Space (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.androidauthority.com%2Fgoogle-pixel-gemini-space-first-look-apk-teardown-3577101%2F%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/0NeYfHQrq5qkz0eUe-7deQkupGsDQFuxieRBN9_KJvs=413
**TLDR Summary:** Gemini Space, which shows contextual cards on the lock screen and other places, currently only displays sports and birthday cards, but finance and Daily Hub features are expected in the future.
**Full Article Content:**
Aamir Siddiqui / Android Authority

TL;DR Gemini Space is an upcoming upgrade to the Pixel’s At a Glance experience.

It’s seemingly inspired by Samsung’s Now bar and Now Brief, which show contextual cards on the lock screen and other places.

In its current state, Gemini Space displays sports and birthday cards, but finance and Daily Hub features are expected in the future.

We’ve previously spotted Google working on a feature called Gemini Space for Pixel devices. Based on the handful of clues we could spot, we speculated that it could be Google’s version of Samsung’s Now Bar and Now Brief features. Now, we’ve managed to activate Gemini Space, giving you the first look at what is indeed a Now Bar-inspired upgrade to Pixel’s At a Glance experience.

Authority Insights story on Android Authority. Discover You're reading anstory on Android Authority. Discover Authority Insights for more exclusive reports, app teardowns, leaks, and in-depth tech coverage you won't find anywhere else. An APK teardown helps predict features that may arrive on a service in the future based on work-in-progress code. However, it is possible that such predicted features may not make it to a public release.

Thanks to the latest Android Canary build, we could activate Gemini Space on a Pixel 9, showing us a sports card and a birthday wish for an upcoming birthday.

Gemini Space cards will also show up on the lock screen. You can see the cards in action when using a large clock and a small clock style in these screenshots:

The cards also appear on the Always On Display, as you can see in these photos:

Gemini Space should be able to show Sports, Finance, and the newly spotted Daily Hub cards, but we haven’t gotten Finance and Daily Hub to work just yet. The feature is still a work in progress, and we expect its functionality to grow and mature as it gets closer to public release. Google hasn’t yet announced the feature, so we don’t know when it’s coming either. We’ll keep you updated when we learn more.

Got a tip? Talk to us! Email our staff at Email our staff at news@androidauthority.com . You can stay anonymous or get credit for the info, it's your choice.

---

### iPhone
 17 May See 'Significant' Dynamic Island Changes (1 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.macrumors.com%2F2025%2F07%2F14%2Fiphone-17-dynamic-island-changes%2F%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/CWIVMNwIZkAwB3TdUnpk38ZQcxlBj5H4nhJ2G11cHb4=413
**TLDR Summary:** Apple appears to be committed to making the Dynamic Island more functional and integrated, turning it into a key element of the user experience.
**Full Article Content:**
The iPhone's Dynamic Island experience is set to undergo "significant evolution" over the next few years, according to a new rumor.



Earlier this month, a report suggested that the iPhone 17 lineup will feature a redesigned Dynamic Island user interface, but little else was explained about the software changes. Now, the leaker known as "Majin Bu" appears to have corroborated this, commenting in a new interview:

I can reveal that the Dynamic Island is set for a significant evolution in the coming years. Apple appears committed to making it more functional and integrated, turning it into a key element of the user experience. This development could mark a step forward in device interaction, but for now, I'll keep further details under wraps. Stay tuned to see how this innovation unfolds.

Overall, it sounds like there is a decent chance that the ‌Dynamic Island‌ will change in some way on ‌iPhone 17‌ models, for the first time since the feature was introduced on the ‌iPhone‌ 14 Pro models in 2022. Apple is now expected to unveil the ‌iPhone 17‌ series during the week of September 8, 2025.

---

### Elon Musk
 Floats a New Source of Funding for xAI: Tesla (4 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2Fz15Fsu/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/9iSe-uP3ESq-FSCIYfCG0dTqATTr9GTqYjZuqM2yYuw=413
**TLDR Summary:** Tesla shareholders will soon be voting on whether to invest in xAI.
**Full Article Content:**
[Scraping failed for this URL. Error: Article `download()` failed with 401 Client Error: HTTP Forbidden for url: https://www.wsj.com/tech/elon-musk-floats-a-new-source-of-funding-for-xai-tesla-47eec67e?st=aoWRXm&reflink=desktopwebshare_permalink&utm_source=tldrnewsletter on URL https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2Fz15Fsu/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/9iSe-uP3ESq-FSCIYfCG0dTqATTr9GTqYjZuqM2yYuw=413]

---

### LLM
 Daydreaming (15 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgwern.net%2Fai-daydreaming%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/ci4_fy4ZfrdFa6bL2dkJfdhfDPyOpfjec89u_Hc4MI4=413
**TLDR Summary:** Despite their vast knowledge and high benchmark scores, no large language model has made a major breakthrough or unexpected insight - this post discusses a theoretical method for making models more insightful.
**Full Article Content:**
The strategic implication is counterintuitive: to make AI cheaper and faster for end users, we might first need to build systems that spend most of their compute on this “wasteful” background search. This suggests a future where expensive, daydreaming AIs are used primarily to generate proprietary training data for the next generation of efficient models, offering a path around the looming data wall.

The cost of this process—a “daydreaming tax”—would be substantial, given the low hit rate for truly novel connections. This expense, however, may be the necessary price for innovation. It would also create a moat against model distillation, as valuable insights emerge from the combinations no one would know to ask for.

To solve this, I propose a day-dreaming loop (DDL) : a background process that continuously samples pairs of concepts from memory. A generator model explores non-obvious links between them, and a critic model filters the results for genuinely valuable ideas. These discoveries are fed back into the system’s memory, creating a compounding feedback loop where new ideas themselves become seeds for future combinations.

A reason may be that they lack some fundamental aspects of human thought: they are frozen, unable to learn from experience, and they have no “default mode” for background processing, a source of spontaneous human insight.

…I feel I am nibbling on the edges of this world when I am capable of getting what Picasso means when he says to me—perfectly straight-facedly—later of the enormous new mechanical brains or calculating machines:

Dwarkesh Patel asks why no LLM has (apparently) ever made a major breakthrough or unexpected insight, no matter how vast their knowledge or how high their benchmark scores. While those are, by definition, extremely rare, contemporary chatbot-style LLMs have now been used seriously by tens of millions of people since ChatGPT (November 2022), and it does seem like there ought to be at least some examples at this point. This is a genuine puzzle: when prompted with the right hints, these models can synthesize information in ways that feel tantalizingly close to true insight; the raw components of intelligence seem to be present; but… they don’t. What is missing?

It’s hard to say because there are so many differences between LLMs and human researchers.

Often these eruptions have nothing at all to do with anything we have been thinking about, or have thought about in decades (“wait—back at that college party, when that girl looked at my hand— she was hitting on me , wasn’t she?”) Indeed, this essay is itself the product of such an eruption—“what is the LLM equivalent of a default mode network? Well, it could look something like Jones , couldn’t it?”—and had nothing to do with what I had been writing about (the esthetics of video games).

Research on science & creativity emphasizes the benefit of time & sleep in creating effects like the incubation effect , and some researchers have famously had sudden insights from dreams. And we have all had the experience of a thought erupting into consciousness, whether it’s just an inane pun (“you can buy kohl at Kohl’s , LOL”), a clever retort hours too late , a frustrating word finally coming to mind, suddenly recalling anxious worries (“did I really turn off the stove?”) like intrusive thoughts , or, once in a lifetime, a brilliant idea. (Try meditating for the first time and writing down all the thoughts that pop up until they finally stop coming, and one may be amazed & frustrated!)

But another notable difference is that human researchers never stop thinking. We are doing our continual learning on not just observations, but on our own thoughts—even when asleep, a human is still computing and processing. (This helps account for the shocking metabolic demands of even a brain which is ‘doing nothing’ —it’s actually still doing a lot! As difficult as it may feel to think hard, from a biological perspective, it’s trivial.)

That may be an adequate answer all on its own: they are trapped in their prior knowledge, and cannot move far beyond their known knowledge; but by definition, all that is either known or almost known, and cannot be impressively novel.

So perhaps that’s a reason they struggle to move beyond their initial guesses or obvious answers, and come up with truly novel insights—in a very real sense, LLMs are unable to learn. They are truly amnesiac. And there are no cases anywhere in human history, as far as I am aware, of any human with anterograde amnesia producing major novelties.

Frozen NNs are amnesiacs. One salient difference is that LLMs are ‘frozen’, and are not allowed to change; they don’t have to be, and could be trained on the fly (eg by the longstanding technique of dynamic evaluation ), but they aren’t.

So… where & when & how does this thinking happen?

It is clearly not happening in the conscious mind. It is also involuntary: you have no idea some arcane random topic is bubbling up in your mind until it does, and then it is too late.

And it is a universal phenomenon: they can happen spontaneously on seemingly any topic you have learned about. It seems difficult to exhaust—after a lifetime, I still have the same rate, and few people report ever having no such thoughts (except perhaps after highly unusual experiences like psychedelics or meditative enlightenment).

It is also probably expensive, given the cost of the brain and the implication that nontrivial thought goes into each connection. It is hard to tell, but my guess is that almost all animals do not have ‘eureka!’ moments. We can further guess that it is probably parallelizable, because the connections are between such ‘distant’ pairs of concepts that it is hard to imagine that the brain has a very large prior on them being related and is only doing a handful of serial computations in between each ‘hit’; they are probably extremely unlikely to be related, hence, many of them are being done, hence, they are being done in parallel to fit into a human lifetime.

It is presumably only partially related to the experience replay done by the hippocampus during sleep, because that is for long-term memory while we have these thoughts about things in Working memory or short-term memory (eg about things during the day, before any sleep); there may well be connections, but they are not the same thing. And it is likely related to the default mode network, which activates when we are not thinking anything explicitly, because that is strongly associated with daydreaming or ‘woolgathering’ or ‘zoning out’, which is when such thoughts are especially likely to erupt. (The default mode network is especially surprising because there is no reason to expect the human brain to have such a thing, rather than go quiescent, and indeed, it took a long time for neuroscientists to accept its existence. And there is little evidence for a default mode network outside primates and possibly some mammals like rats.)

It further appears to be ‘crowded out’ and probably not happening when doing ‘focused’ learning or thinking: in my personal observation, when I have been intensively doing something (whether reading research, writing, coding, or anything else novel & intellectually demanding), the thoughts stop happening… but if I take a break, they may suddenly surge, as if there was a dam holding them back or my brain is making up for lost time.

So where is it?

---

### Cognition,
 maker of the AI coding agent Devin, acquires Windsurf (5 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F07%2F14%2Fcognition-maker-of-the-ai-coding-agent-devin-acquires-windsurf%2F%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/oTnqqNLL7vpPQwS1a3Vyxl2PubS5PxxfPEJcN5D3MzA=413
**TLDR Summary:** Google recently hired away Windsurf's CEO, co-founder, and research leaders but left most of the startup's 250-person team behind.
**Full Article Content:**
Cognition, the startup behind the viral AI coding agent Devin, announced in a blog post on Monday that it has signed a definitive agreement to acquire AI coding startup Windsurf.

The announcement comes just days after Google hired away Windsurf’s CEO Varun Mohan, co-founder Douglas Chen, and research leaders in a $2.4 billion reverse-acquihire that left much of the startup’s 250-person team behind. Google’s deal occurred just hours after OpenAI’s $3 billion offer to acquire Windsurf expired, clearing the way for the AI coding startup to explore other options.

The frenzy around Windsurf represents a new peak in the wild race to develop AI coding tools — specifically, the AI-powered integrated development environments (IDEs) that Cursor and Windsurf offer. In recent months, the businesses around AI-powered IDEs have skyrocketed, pushing Cursor’s annualized recurring revenue (ARR) to $500 million. While Windsurf’s business is smaller than Cursor’s, it has achieved impressive growth in the last year, garnering interest from several larger companies.

“The last 72 hours have been the wildest rollercoaster ride of my career,” said Jeff Wang, Windsurf’s former head of business, who was made interim CEO of the startup days ago after Google hired the startup’s leaders, in a post on LinkedIn. “To our new teammates at Cognition: we at Windsurf feel incredibly lucky to be joining a team that shares our vision, our deep commitment to our users, and — most importantly — our values.”

Cognition says it’s acquiring Windsurf’s IP and product, which include its AI-powered IDE, alongside all of the employees who were not hired by Google.

Cognition did not announce the price it acquired Windsurf for; however, the company says Windsurf reached $82 million in ARR, with enterprise ARR doubling quarter-over-quarter. Cognition says Windsurf’s user base reached at least 350 enterprise customers and “hundreds of thousands” of daily active users.

In the near term, Windsurf’s team will continue working on its AI-powered IDE, while Cognition works on its AI coding agent, Devin, the companies said in a press release. Eventually, Cognition says it will integrate Windsurf’s IP and capabilities into its own products.

TechCrunch reported in April that Windsurf’s ARR had reached $100 million at one point. However, Anthropic — which offers some of the most popular AI models for coding tasks — cut Windsurf’s direct access to its Claude AI models in June, with Anthropic co-founder Jared Kaplan attributing the decision to rumors that OpenAI, its largest competitor, was close to acquiring Windsurf. Several Windsurf customers told TechCrunch they switched to other services that offered Claude AI models, such as Cursor, in light of the incident.

Cognition notes in its press release that Windsurf will now have full access to Claude AI models once again.

Over the weekend, The Information reported that Windsurf employees who had joined in the last year did not receive a payout in Google’s billion-dollar reverse-acquihire. That prompted many users on social media to scoff at the deal, which seemed to largely benefit investors and leaders at the startup.

Cognition president Russell Kaplan indicated in a post on X that the Windsurf acquisition truly came together over the weekend, just hours after the Google deal was made public. He noted that the first call was made after 5 p.m. on Friday and that an agreement was signed Monday morning.

Incredibly excited to share that Cognition is acquiring Windsurf. What an insane weekend – from first call after 5pm on Friday to a signed definitive agreement this morning. There’s a lot to build! https://t.co/UxwOG3QHVg — Russell Kaplan (@russelljkaplan) July 14, 2025

Cognition notes in its blog post that 100% of Windsurf employees will participate financially in this deal and have vesting cliffs waived for their work to date.

With the addition of Windsurf’s talent and IP, Cognition may have a supercharged startup to compete with giants in the AI coding space, such as OpenAI, Anthropic, and Cursor. In March, Cognition reportedly held talks to raise hundreds of millions of dollars at a $4 billion valuation. It’s unclear if the round closed, but Cognition may need such a war chest to compete in the AI coding space.

Cognition was one of the first AI startups to launch a fully fledged AI coding agent, Devin, which didn’t just help with tasks, but also promised to automate them completely as if it were a junior software engineer. This was a markedly bold approach compared to Cursor and Windsurf, which offered environments for developers to easily access AI tools. However, early reviews found that Devin made mistakes, perhaps indicating that its AI agent technology was ahead of its time.

That may no longer be the case. In recent months, Cursor and Windsurf have started offering more agentic AI products that are starting to resemble what Cognition offers. In a recent interview, Cursor CEO Michael Truell said he believes AI reasoning models are advancing enough to make coding agents viable and that he expects 20% of coding workflows to be handled by agents by 2026.

Now Cognition has the versatility of offering both AI coding agents and an AI-powered IDE, perhaps enhancing its value proposition. Earlier this week, Cognition also landed a major customer in the Wall Street juggernaut Goldman Sachs.

With the acquisition of Windsurf, it seems Cognition has become a more serious competitor in the AI coding space.

Update: A previous version of this article misstated what Windsurf’s team will be doing at Cognition in the near term. This article was updated on July 14 to note that Windsurf’s team will continue its normal work for now, and will eventually integrate its products into Cognition’s offerings. We regret the error.

---

### How
 GLP-1s Are Breaking Life Insurance (7 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.glp1digest.com%2Fp%2Fhow-glp-1s-are-breaking-life-insurance%3Futm_source=tldrnewsletter/1/010001980db0acbb-7f93f144-5277-4921-bb22-ff6df30b7d52-000000/7MTkTGXAleuld0rPyYN5vz9jeYsptfjjCMmdtJGOJ1E=413
**TLDR Summary:** A person purchasing health insurance while on GLP-1 drugs may be assessed at the same level as someone at the same health level who isn't on the drug, but the person on GLP-1 is likely to return to their previous state of health within two years of stopping the medication.
**Full Article Content:**
GPT/GLP-1 Illustration

Hello and happy Sunday! Was this newsletter forwarded to you? Sign up to get it in your inbox.

I've just got back from HLTH in Amsterdam, nursing what might be the worst three-day hangover of my adult life. Worth it, though. It's one of the best health tech events in Europe, and I made some genuinely great connections.

If you’re ever at a large health conference, here’s a neat little hack I learned: Be brave enough to ask questions during panels. It's terrifying, but suddenly everyone knows your name, your company, and that you've got enough spine to speak up in front of 200 people. Makes the networking infinitely easier afterward.

Now, while everyone else obsessed over AI (shocking, I know), I was laser-focused on GLP-1s. One throwaway comment during a private equity panel sent me down a rabbit hole on insurance companies grappling with the weight-loss drug explosion.

The downstream effects are completely fascinating and completely overlooked. I spent the rest of the conference hunting down insurance people who were all asking the same question: how the hell do we deal with this?

Turns out, they have good reason to panic.

Life insurers can predict when you'll die with about 98% accuracy.

This ruthless precision comes from from decades and decades of mortality data they use to figure out how much to charge you every year, so that the money they earn (from you and by investing your premiums) will easily cover what they'll need to pay out later.

Of course, not everyone gets the same deal.

Underwriting is the dark art that allows an insurer to figure out if you're a good bet or a risky one.

Typically, underwriters- suspiciously sounds like undertakers-rely on a handful of key health metrics like HbA1c, cholesterol, blood pressure, and BMI to calculate your risk of dying earlier than expected (and thus costing them money).

Those eagle-eyed readers among you have probably noticed something interesting already. Those same four metrics are exactly what GLP‑1s improve. Not just a little, but enough to entirely shift someone's risk profile within at least 6 months of using them.

So, what’s the issue?

Let’s say a 42-year-old applies for life insurance:

They self-report a BMI of 25 (healthy)

No visible co-morbidities in claims data

No prescription record shows Sema/Tirzepatide

Labs within normal range

The insurer sees a ‘mirage’ of good health and approves them as low-risk.

But in reality:

They were obese a year ago (BMI 32)

Lost around 14kg using GLP-1s from a D2C provider (no detail on their electronic health record)

Still have underlying metabolic syndrome

If we assume about 65% of people who start GLP-1 medications quit by the end of year one, that creates a big problem. When someone stops the medication, they'll usually regain the weight they lost, and in two years, most of those key health indicators (like BMI, blood pressure, blood sugar and cholesterol) bounce back to their starting point.

This means the underwriter has just locked in a 30-year policy at preferred rates for someone who'll be high-risk again by year three.

Insurers call this type of screw-up "mortality slippage."

Mortality slippage means accidentally classifying someone as lower-risk than they actually are. It's ridiculously expensive. A single mistaken classification can cost insurers millions in unexpected payouts over the life of a policy.

And it's getting worse. Fast. Mortality slippage has exploded since 2019, nearly tripling from 5.8% to a staggering 15.3%. That means one in six life insurance policies is fundamentally mis-priced.

Missed Declines (dark green bars): Insurers failed to detect deteriorating health conditions. Source: SwissRe

How are insurers responding?

The first thing insurers are doing is changing their assessments.

Instead of asking something vague like “How much has your weight changed in the past 12 months?”, which forces you to think hard and guess and probably lie, underwriters are using a behavioural-science technique called anchoring to simplify things.

Now, they'd say something like, “In the past 12 months, has your weight changed by more than 10kg because of weight-loss medication?” By adding a clear reference (the "10kg" anchor), underwriters make it easier and more likely for people to answer truthfully.

If you answer honestly (many don’t), insurers are responding in one of three ways:

Denying coverage completely

Requiring proof you can sustain weight loss on GLP-1s for at least a year

Adding 2-3 BMI points to your risk profile as a safety buffer

Real life patient. Many such cases.

Of course, these are band-aid solutions to a retention problem. And retention problems create massive business opportunities

The Real Money

Right now, insurers see GLP-1s as short-term weight-loss tools because that's exactly how patients treat them.

Source: Supplementary findings from the OBSERVE Study

But we know that there’s rock solid data showing continued GLP-1 use does significantly reduce obesity, cardiovascular disease, and overall mortality (indirectly).

In other words, better adherence leads to healthier patients who cost insurers far less over the long term.

Insures are already starting to hunt aggressively for these partnerships because this stabilizes their financial projections and reduces expensive claims down the line.

These partnerships could easily become multimillion-dollar deals, once generics and new GLP-1 entrants push prices down, opening the door to serving hundreds of thousands of customers every month and making this a fantastic win-win-win situation for patients, insurers and private companies.

But at HLTH, when I asked how companies planned to actually deliver this retention, all I heard were vague promises about "wrap-around care" being some kind of magical bullet.

When pressed for specifics—or actual, hard data proving it works—I didn't get a single convincing answer.

Don’t get me wrong. I do agree with the value of wrap around care. I do.

But my issue is we tend to overcomplicate solutions because we're drawn to elaborate, multi-layered strategies (umm, look at how much the NHS spent on McKinsey) when simpler fixes have worked brilliantly in the past.

If we look at statins, there was clear evidence they prevented heart attacks, yet patients kept quitting on them.

The industry wrung its hands about "patient education" and "compliance programs" while completely missing the obvious solution.

Make getting them less of a pain in the ass.

They switched from 30-day to 90-day refills. Suddenly, patients had to think about their medication four times a year instead of twelve. Adherence rates shot up almost immediately.

The same principle could be applied very powerfully to GLP-1 meds.

Alongside thoughtful wrap-around services, there's enormous value in:

3 month bundles of the same dose of medication

minimal friction for restarting paused treatments

behavioural nudges like text notifications

I think this would have an immediate impact & cost much, much less for the patient and for your margin.



Conclusion

Right now, insurers are getting fooled by mirages of good health that disappear when people quit treatment. The companies that turn those mirages into reality, by you know, actually keeping people on medication, will be solving a problem that insurers will want to throw money at.

But this window won't stay open forever. Insurers are already adapting, asking harder questions, building better detection systems. The first movers who crack retention before insurers figure out their own solutions will capture the entire market and become the industry standard.

The statin playbook worked 20 years ago. It'll work again today, but only for those who execute it first.

---

