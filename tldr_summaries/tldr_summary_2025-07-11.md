# TLDR Newsletter Summary: 2025-07-11

## TLDR2025-07-11

### Level-up
 your security with confidence (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.vanta.com%2Freports%2Ftrust-maturity-report%3Futm_campaign=trust-maturity-report%26utm_source=tldr%26utm_medium=newsletter/2/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/ZObl664ZjXzHXtqf4Ae-m4TGoMB3gUQdJvIfGo1RBSs=413
**TLDR Summary:** As you scale your business, security needs to be more than a checkbox—it should be the foundation for customer trust and long-term growth. Vanta's Trust Maturity Report helps you benchmark your security program against your peers so you can level up your security with confidence. Aligned to the NIST CSF maturity tiers, this report uses customer insights and aggregated, anonymized data from Vanta's 11,000+ customers. Vanta helps companies of all sizes achieve compliance quickly and painlessly by automating 35+ frameworks—including SOC 2, ISO 27001, HIPAA, CMMC, and more. And with Vanta continuously monitoring your security posture, your team can focus on growth, stay ahead of evolving regulations, and close deals in a fraction of the time. See what your security program may be missing by downloading the report .
**Full Article Content:**
Advice from a Vanta customer:

“ Automate as much as possible. Security is obviously important but can be a huge time suck for the whole organization unless you have structure and automation.”

---

## Big Tech & Startups

### Foldable
 iPhone Display Production Begins Ahead of Launch Next Year (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.macrumors.com%2F2025%2F07%2F10%2Ffoldable-iphone-display-production-begins%2F%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/sK2WC0qVf4D1CbAmonZmdMwDnhap-CH1XQkZ7brKATA=413
**TLDR Summary:** Apple's first foldable iPhone OLED displays have begun production ahead of an expected launch next year. The phone is expected to feature an inward-folding OLED display and be refreshed annually in the fall, just like the other models. Apple plans to produce six to eight million foldable iPhones in 2026. Samsung Display has secured an agreement to provide Apple with foldable displays as the sole supplier for several years.
**Full Article Content:**
Production of foldable OLED displays for Apple's first foldable iPhone have begun ahead of its expected launch next year, Korea's ETNews reports.



The first foldable ‌iPhone‌'s displays are being produced by Samsung Display, who are establishing a production line dedicated to the upcoming Apple device its A3 factory in Asan, Chungcheongnam-do. The production line will make displays exclusively for the foldable ‌iPhone‌ and work on the facility is now believed to be in its final stage. It will be capable of producing 15 million 7-inch foldable OLED panels per year.

Apple's first foldable ‌iPhone‌ is expected to feature an inward-folding OLED display. It will likely sit alongside the other models in next year's ‌iPhone‌ lineup, including the iPhone 18, ‌iPhone 18‌ Air, ‌iPhone 18‌ Pro, and ‌iPhone 18‌ Pro Max. It will be refreshed annually in the fall just like the other models.

Apple is apparently planning to produce six to eight million foldable iPhones in 2026. While Samsung's production capacity of 15 million displays per year far exceeds Apple's requirements for 2026, the supplier is said to be preparing for new models and increasing sales in subsequent years.

Samsung Display apparently has secured an agreement with provide Apple with foldable displays as the sole supplier for several years. While Apple usually prefers to diversify its supply chain where possible, Samsung has unique technological expertise in foldable OLED displays due to offering its own foldable smartphones, which it has been making commercially since 2019.

As a result, Samsung is likely to remain the exclusive supplier of Apple's foldable ‌iPhone‌ displays for some time and a least be a key supplier thereafter. Samsung Display similarly led Apple's transition from LCD to OLED with the ‌iPhone‌ X and ‌iPhone‌ XS.

Apple's first foldable ‌iPhone‌ is expected to feature a super-thin design at 4.5mm, a 4:3 iPad-style 7-inch inner display with no visible crease, a durable hinge, a dual rear camera system with wide and ultra wide options, the "A20" chip, and Touch ID instead of Face ID. It could cost over $2,000.

---

### Foldable
 iPhone Display Production Begins Ahead of Launch Next Year (2 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.macrumors.com%2F2025%2F07%2F10%2Ffoldable-iphone-display-production-begins%2F%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/sK2WC0qVf4D1CbAmonZmdMwDnhap-CH1XQkZ7brKATA=413
**TLDR Summary:** Apple's first foldable iPhone OLED displays have begun production ahead of an expected launch next year. The phone is expected to feature an inward-folding OLED display and be refreshed annually in the fall, just like the other models. Apple plans to produce six to eight million foldable iPhones in 2026. Samsung Display has secured an agreement to provide Apple with foldable displays as the sole supplier for several years.
**Full Article Content:**
Production of foldable OLED displays for Apple's first foldable iPhone have begun ahead of its expected launch next year, Korea's ETNews reports.



The first foldable ‌iPhone‌'s displays are being produced by Samsung Display, who are establishing a production line dedicated to the upcoming Apple device its A3 factory in Asan, Chungcheongnam-do. The production line will make displays exclusively for the foldable ‌iPhone‌ and work on the facility is now believed to be in its final stage. It will be capable of producing 15 million 7-inch foldable OLED panels per year.

Apple's first foldable ‌iPhone‌ is expected to feature an inward-folding OLED display. It will likely sit alongside the other models in next year's ‌iPhone‌ lineup, including the iPhone 18, ‌iPhone 18‌ Air, ‌iPhone 18‌ Pro, and ‌iPhone 18‌ Pro Max. It will be refreshed annually in the fall just like the other models.

Apple is apparently planning to produce six to eight million foldable iPhones in 2026. While Samsung's production capacity of 15 million displays per year far exceeds Apple's requirements for 2026, the supplier is said to be preparing for new models and increasing sales in subsequent years.

Samsung Display apparently has secured an agreement with provide Apple with foldable displays as the sole supplier for several years. While Apple usually prefers to diversify its supply chain where possible, Samsung has unique technological expertise in foldable OLED displays due to offering its own foldable smartphones, which it has been making commercially since 2019.

As a result, Samsung is likely to remain the exclusive supplier of Apple's foldable ‌iPhone‌ displays for some time and a least be a key supplier thereafter. Samsung Display similarly led Apple's transition from LCD to OLED with the ‌iPhone‌ X and ‌iPhone‌ XS.

Apple's first foldable ‌iPhone‌ is expected to feature a super-thin design at 4.5mm, a 4:3 iPad-style 7-inch inner display with no visible crease, a durable hinge, a dual rear camera system with wide and ultra wide options, the "A20" chip, and Touch ID instead of Face ID. It could cost over $2,000.

---

### Robinhood
 CEO's AI Math Startup Valued at Nearly $900 Million (3 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-10%2Frobinhood-ceo-s-ai-math-startup-valued-at-nearly-900-million%3FaccessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1MjIxNDM2OCwiZXhwIjoxNzUyODE5MTY4LCJhcnRpY2xlSWQiOiJTWjc0OVBUMEFGQjQwMCIsImJjb25uZWN0SWQiOiJFQTExNDNDNTM4NEE0RUY5QTg5RjJEN0IxMTg2MzcwOSJ9.mJrn9SZUcwCq0qK35ofgmUCUIB4j_ujGWXw3M7IN3do%26utm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/-f4nXYthNJ6kZH4-CGUp8HxiK2R-yUSMNmDBGms1OiI=413
**TLDR Summary:** Harmonic AI is an artificial intelligence startup focused on building AI systems that can solve complex math problems. Co-founded by Robinhood's CEO Vlad Tenev, the startup recently raised $100 million in a Series B funding round led by Kleiner Perkins, with participation from Sequoia Capital, Index Ventures, and Paradigm. Harmonic plans to make its flagship AI model available to researchers and the general public later this year. Its ultimate goal is to solve major unsolved mathematical problems and expand that to problems in physics and computer science.
**Full Article Content:**
[Scraping failed for this URL. Error: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.bloomberg.com/news/articles/2025-07-10/robinhood-ceo-s-ai-math-startup-valued-at-nearly-900-million?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1MjIxNDM2OCwiZXhwIjoxNzUyODE5MTY4LCJhcnRpY2xlSWQiOiJTWjc0OVBUMEFGQjQwMCIsImJjb25uZWN0SWQiOiJFQTExNDNDNTM4NEE0RUY5QTg5RjJEN0IxMTg2MzcwOSJ9.mJrn9SZUcwCq0qK35ofgmUCUIB4j_ujGWXw3M7IN3do&utm_source=tldrnewsletter on URL https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-10%2Frobinhood-ceo-s-ai-math-startup-valued-at-nearly-900-million%3FaccessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1MjIxNDM2OCwiZXhwIjoxNzUyODE5MTY4LCJhcnRpY2xlSWQiOiJTWjc0OVBUMEFGQjQwMCIsImJjb25uZWN0SWQiOiJFQTExNDNDNTM4NEE0RUY5QTg5RjJEN0IxMTg2MzcwOSJ9.mJrn9SZUcwCq0qK35ofgmUCUIB4j_ujGWXw3M7IN3do%26utm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/-f4nXYthNJ6kZH4-CGUp8HxiK2R-yUSMNmDBGms1OiI=413]

---

## Science & Futuristic Technology

### Robot
 surgery on humans could be trialled within decade after success on pig organs (4 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.theguardian.com%2Fscience%2F2025%2Fjul%2F09%2Frobot-surgery-on-humans-could-be-trialled-within-decade-after-success-on-pig-organs%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/SovOhJK2sGgWshjfAH5XWB5dwDOVJUDHl9wZprNMJEM=413
**TLDR Summary:** An AI-trained robot recently completed eight operations on pig organs with a 100% success rate. The robot, armed with tools to cut, clip, and grab soft tissue, successfully removed pig gall bladders without human help. They were trained on video footage of human medics conducting operations using organs taken from dead pigs. The success opens up the possibility of replicating, en masse, the skills of the best surgeons in the world.
**Full Article Content:**
Automated surgery could be trialled on humans within a decade, say researchers, after an AI-trained robot armed with tools to cut, clip and grab soft tissue successfully removed pig gall bladders without human help.

The robot surgeons were schooled on video footage of human medics conducting operations using organs taken from dead pigs. In an apparent research breakthrough, eight operations were conducted on pig organs with a 100% success rate by a team led by experts at Johns Hopkins University in Baltimore in the US.

The Royal College of Surgeons in the UK called it “an exciting development that shows great promise”, while John McGrath, a leading expert on robotic surgery in the UK, called the results “impressive” and “novel” and said it “takes us further into the world of autonomy”.

It opens up the possibility of replicating, en masse, the skills of the best surgeons in the world.

The technology allowing robots to handle complex soft tissues such as gallbladders, which release bile to aid digestion, is rooted in the same type of computerised neural networks that underpin widely used artificial intelligence tools such as Chat GPT or Google Gemini.

The surgical robots were slightly slower than human doctors but they were less jerky and plotted shorter trajectories between tasks. The robots were also able to repeatedly correct mistakes as they went along, asked for different tools and adapted to anatomical variation, according to a peer-reviewed paper published in the journal Science Robotics.

The authors from Johns Hopkins, Stanford and Columbia universities called it “a milestone toward clinical deployment of autonomous surgical systems”.

Almost all the 70,000 robotic procedures carried out annually in the NHS in England were fully controlled under human instruction, with only bone-cutting for hip and knee operations semi-autonomous, McGrath said. Last month the health secretary, Wes Streeting, said increasing robotic surgery was at the heart of a 10-year plan to reform the NHS and cut waiting lists. Within a decade, the NHS has said, nine in 10 of all keyhole surgeries will be carried out with robot assistance, up from one in five today.

In the Johns Hopkins trial, the robots took just over five minutes to carry out the operation, which required 17 steps including cutting the gallbladder away from its connection to the liver, applying six clips in a specific order and removing the organ. The robots on average corrected course without any human help six times in each operation.

“We were able to perform a surgical procedure with a really high level of autonomy,” said Axel Krieger, assistant professor of mechanical engineering at Johns Hopkins. “In prior work, we were able to do some surgical tasks like suturing. What we’ve done here is really a full procedure. We have done this on eight gallbladders, where the robot was able to perform precisely the clipping and cutting step of gallbladder removal without any human intervention.

“So I think it’s a really big landmark study that such a difficult soft tissue surgery is possible to do autonomously.”

McGrath, who chairs NHS England’s robotics steering committee, said autonomous surgery, while still years away, could one day lead to a human surgeon overseeing several autonomous robotic operations at the same time, carrying out simple procedures such as hernia operations or gall bladder removals more rapidly, with greater precision than humans and with less damage to surrounding bodily structures.

But he cautioned that autonomous surgery remained a long way from being clinically deployable, because tests on dead pig organs do not test the robots’ capacity to react to a patient moving and breathing, blood running in the field of operation, an inadvertent injury, smoke from cauterisation or fluid on the camera lens.

Nuha Yassin, who leads on robotic surgery at the Royal College of Surgeons of England, said: “The next step must involve a careful exploration of the nuances within this rapidly evolving field to assess how these findings can be safely and effectively translated into a human pilot. Only then can this approach move toward, becoming a sustainable model for the future.”

She said training, education and patient safety must remain at the forefront.

---

### Robot
 surgery on humans could be trialled within decade after success on pig organs (4 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.theguardian.com%2Fscience%2F2025%2Fjul%2F09%2Frobot-surgery-on-humans-could-be-trialled-within-decade-after-success-on-pig-organs%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/SovOhJK2sGgWshjfAH5XWB5dwDOVJUDHl9wZprNMJEM=413
**TLDR Summary:** An AI-trained robot recently completed eight operations on pig organs with a 100% success rate. The robot, armed with tools to cut, clip, and grab soft tissue, successfully removed pig gall bladders without human help. They were trained on video footage of human medics conducting operations using organs taken from dead pigs. The success opens up the possibility of replicating, en masse, the skills of the best surgeons in the world.
**Full Article Content:**
Automated surgery could be trialled on humans within a decade, say researchers, after an AI-trained robot armed with tools to cut, clip and grab soft tissue successfully removed pig gall bladders without human help.

The robot surgeons were schooled on video footage of human medics conducting operations using organs taken from dead pigs. In an apparent research breakthrough, eight operations were conducted on pig organs with a 100% success rate by a team led by experts at Johns Hopkins University in Baltimore in the US.

The Royal College of Surgeons in the UK called it “an exciting development that shows great promise”, while John McGrath, a leading expert on robotic surgery in the UK, called the results “impressive” and “novel” and said it “takes us further into the world of autonomy”.

It opens up the possibility of replicating, en masse, the skills of the best surgeons in the world.

The technology allowing robots to handle complex soft tissues such as gallbladders, which release bile to aid digestion, is rooted in the same type of computerised neural networks that underpin widely used artificial intelligence tools such as Chat GPT or Google Gemini.

The surgical robots were slightly slower than human doctors but they were less jerky and plotted shorter trajectories between tasks. The robots were also able to repeatedly correct mistakes as they went along, asked for different tools and adapted to anatomical variation, according to a peer-reviewed paper published in the journal Science Robotics.

The authors from Johns Hopkins, Stanford and Columbia universities called it “a milestone toward clinical deployment of autonomous surgical systems”.

Almost all the 70,000 robotic procedures carried out annually in the NHS in England were fully controlled under human instruction, with only bone-cutting for hip and knee operations semi-autonomous, McGrath said. Last month the health secretary, Wes Streeting, said increasing robotic surgery was at the heart of a 10-year plan to reform the NHS and cut waiting lists. Within a decade, the NHS has said, nine in 10 of all keyhole surgeries will be carried out with robot assistance, up from one in five today.

In the Johns Hopkins trial, the robots took just over five minutes to carry out the operation, which required 17 steps including cutting the gallbladder away from its connection to the liver, applying six clips in a specific order and removing the organ. The robots on average corrected course without any human help six times in each operation.

“We were able to perform a surgical procedure with a really high level of autonomy,” said Axel Krieger, assistant professor of mechanical engineering at Johns Hopkins. “In prior work, we were able to do some surgical tasks like suturing. What we’ve done here is really a full procedure. We have done this on eight gallbladders, where the robot was able to perform precisely the clipping and cutting step of gallbladder removal without any human intervention.

“So I think it’s a really big landmark study that such a difficult soft tissue surgery is possible to do autonomously.”

McGrath, who chairs NHS England’s robotics steering committee, said autonomous surgery, while still years away, could one day lead to a human surgeon overseeing several autonomous robotic operations at the same time, carrying out simple procedures such as hernia operations or gall bladder removals more rapidly, with greater precision than humans and with less damage to surrounding bodily structures.

But he cautioned that autonomous surgery remained a long way from being clinically deployable, because tests on dead pig organs do not test the robots’ capacity to react to a patient moving and breathing, blood running in the field of operation, an inadvertent injury, smoke from cauterisation or fluid on the camera lens.

Nuha Yassin, who leads on robotic surgery at the Royal College of Surgeons of England, said: “The next step must involve a careful exploration of the nuances within this rapidly evolving field to assess how these findings can be safely and effectively translated into a human pilot. Only then can this approach move toward, becoming a sustainable model for the future.”

She said training, education and patient safety must remain at the forefront.

---

### Tesla
 moves to expand Robotaxi to Phoenix, following rival Waymo (3 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.cnbc.com%2F2025%2F07%2F10%2Ftesla-moves-to-expand-robotaxi-to-phoenix-following-rival-waymo.html%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/KNWS5oLwzrmnj5xzXh3vNQ8_Y-BLJrKH2_0XTzZbSiU=413
**TLDR Summary:** Tesla has applied to test and eventually deploy its robotaxis in Phoenix, Arizona. A decision on the application is expected at the end of July. Tesla began a pilot test of its robotaxis in Austin, Texas, in June. Those vehicles are remotely supervised by employees in an undisclosed operations center, and they each include a human safety supervisor, who rides with the passengers.
**Full Article Content:**
Elon Musk's Tesla has applied to test and eventually deploy its Robotaxi vehicles in Phoenix, Arizona, following in the footsteps of market leader Waymo.

Tesla has applied to conduct autonomous vehicle testing and operations, with and without human safety drivers on board, in Arizona, a spokesperson for the Arizona Department of Transportation told CNBC on Thursday. A decision on the application is expected at the end of July, and Tesla has "expressed interest in operating within the Phoenix Metro area," the spokesperson said via email.

Reuters first reported Tesla's Arizona ambitions.

The effort to expand to Arizona comes after Tesla in June began a pilot test of its robotaxis in Austin, Texas. Tesla's Austin fleet includes Model Y SUVs that are equipped with the company's newest, automated driving systems. Those vehicles are remotely supervised by employees in an undisclosed operations center, and they each include a human safety supervisor who rides with passengers.

The safety supervisor sits in the front passenger seat, accompanying riders, who are invited fans of Tesla. The supervisor can intervene should the Tesla Robotaxis get into trouble.

Waymo, owned by Google parent Alphabet , opened up a driverless robotaxi service to the public in the Phoenix area in 2020, and now operates a fleet of 400 robotaxis there, the company told CNBC on Thursday.

Tesla, which was once seen as a self-driving pioneer, is now working to catch up to Waymo. The companies have distinct approaches to self-driving technology. Tesla claims its choice to mostly use cameras instead of expensive sensors like lidar will make its autonomous vehicles more economically viable.

The Musk company's initial efforts in Austin have run into issues.

One invited passenger, who runs a Tesla-focused YouTube channel called Dirty Tesla, captured an incident on camera where his Robotaxi dinged a parked car outside of a restaurant.

Other incidents where Tesla Robotaxis violated rules of the road in Austin have also been captured on camera and circulated on social media, drawing regulatory scrutiny from the National Highway Traffic Safety Administration, the federal vehicle safety agency.

Tesla is scheduled to hold a second-quarter earnings call on July 23, during which executives are expected to discuss the initial Robotaxi pilot.

Separately, Musk on Wednesday said on X that Tesla's Robotaxi service will expand to the San Francisco Bay Area "probably in a month or two."

California Public Utilities Commission and the California Department of Motor Vehicles told CNBC on Thursday that Tesla has not yet applied for approvals to begin driverless testing or commercial deployment of its Robotaxis in the state.

The California DMV sued Tesla in 2022 alleging that the company made false claims in marketing and advertising about its vehicles' self-driving capabilities.

WATCH: We went to Texas for Tesla's robotaxi launch. Here's what we saw

---

## Programming, Design & Data Science

### AI
 in software engineering at Google: Progress and the path ahead (6 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fresearch.google%2Fblog%2Fai-in-software-engineering-at-google-progress-and-the-path-ahead%2F%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/BU7sqxGBYwhQbZdcymLsrKbfaGIWMIKqAGRDi0D4V2Q=413
**TLDR Summary:** This post discusses Google's newest AI-powered improvements and discusses further changes the company expects to see in the coming five years. It also presents a methodology for building AI products that deliver value for professional software development. Improving these surfaces can directly impact developer productivity and satisfaction.
**Full Article Content:**
In 2019, a software engineer — at Google or indeed anywhere else — would have heard of advances in machine learning, and how deep learning has become remarkably effective in fields such as computer vision or language translation. However, most of them would not have imagined, let alone experienced, the ways in which machine learning might benefit what they do.

Just five years later, in 2024, there is widespread enthusiasm among software engineers about how AI is helping write code. And a significant number of those have used ML-based autocomplete, whether it is using company internal tools at large companies, e.g., Google’s internal code completion, or via commercially available products.

In this blog, we present our newest AI-powered improvements within the context of the continuing transformation of Google’s internal software development tools, and discuss further changes that we expect to see in the coming 5 years. We also present our methodology on how to build AI products that deliver value for professional software development. Our team is responsible for the software development environments where Google engineers spend the majority of their time, including inner loop (e.g., IDE, code review, code search), as well as outer loop surfaces (e.g., bug management, planning). We illustrate that improvements to these surfaces can directly impact developer productivity and satisfaction, both metrics that we monitor carefully.

---

### AI
 in software engineering at Google: Progress and the path ahead (6 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fresearch.google%2Fblog%2Fai-in-software-engineering-at-google-progress-and-the-path-ahead%2F%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/BU7sqxGBYwhQbZdcymLsrKbfaGIWMIKqAGRDi0D4V2Q=413
**TLDR Summary:** This post discusses Google's newest AI-powered improvements and discusses further changes the company expects to see in the coming five years. It also presents a methodology for building AI products that deliver value for professional software development. Improving these surfaces can directly impact developer productivity and satisfaction.
**Full Article Content:**
In 2019, a software engineer — at Google or indeed anywhere else — would have heard of advances in machine learning, and how deep learning has become remarkably effective in fields such as computer vision or language translation. However, most of them would not have imagined, let alone experienced, the ways in which machine learning might benefit what they do.

Just five years later, in 2024, there is widespread enthusiasm among software engineers about how AI is helping write code. And a significant number of those have used ML-based autocomplete, whether it is using company internal tools at large companies, e.g., Google’s internal code completion, or via commercially available products.

In this blog, we present our newest AI-powered improvements within the context of the continuing transformation of Google’s internal software development tools, and discuss further changes that we expect to see in the coming 5 years. We also present our methodology on how to build AI products that deliver value for professional software development. Our team is responsible for the software development environments where Google engineers spend the majority of their time, including inner loop (e.g., IDE, code review, code search), as well as outer loop surfaces (e.g., bug management, planning). We illustrate that improvements to these surfaces can directly impact developer productivity and satisfaction, both metrics that we monitor carefully.

---

### How
 much AI coding tools speed up experienced open-source developers (1 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fthreadreaderapp.com%2Fthread%2F1943360399220388093.html%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/VqnJSo7NtnYZ6lGqGXXrgOoQErNHz_gVAA47mGZwGS8=413
**TLDR Summary:** A randomized controlled trial found that developers were actually 19% slower when they had access to AI than when they didn't. The results were surprising, as developers thought they were 20% faster with AU tools. The study asked 16 developers with moderate AI experience to complete 246 tasks in large and complex projects on which they had an average of five years of prior experience. A chart showing the results of the study is available.
**Full Article Content:**
Bookmark Save as PDF





The results surprised us: Developers thought they were 20% faster with AI tools, but they were actually 19% slower when they had access to AI than when they didn't. We ran a randomized controlled trial to see how much AI coding tools speed up experienced open-source developers.The results surprised us: Developers thought they were 20% faster with AI tools, but they were actually 19% slower when they had access to AI than when they didn't.





We randomly assigned each task to either allow AI (typically Cursor Pro w/ Claude 3.5/3.7) or disallow AI help. We recruited 16 experienced open-source developers to work on 246 real tasks in their own repositories (avg 22k+ stars, 1M+ lines of code).We randomly assigned each task to either allow AI (typically Cursor Pro w/ Claude 3.5/3.7) or disallow AI help.

At the beginning of the study, developers forecasted that they would get sped up by 24%. After actually doing the work, they estimated that they had been sped up by 20%. But it turned out that they were actually slowed down by 19%.

We were surprised by this, given a) impressive AI benchmark scores, b) widespread adoption of AI tooling for software development, and c) our own recent research measuring trends in the length of tasks that agents are able to complete.

When AI is allowed, developers spend less time actively coding and searching for information, and instead spend time prompting AI, waiting on/reviewing AI outputs, and idle. We find no single reason for the slowdown—it’s driven by a combination of factors.





We also analyze to make sure the result isn’t a fluke, and find that slowdown persists across different outcome measures, estimator methodologies, and many other subsets/analyses of our data.



To better understand these factors, we investigate 20 properties of our setting, finding 5 likely contributors, and 8 mixed/unclear factors.We also analyze to make sure the result isn’t a fluke, and find that slowdown persists across different outcome measures, estimator methodologies, and many other subsets/analyses of our data.

Why did we run this study?



AI agent benchmarks have limitations—they’re self-contained, use algorithmic scoring, and lack live human interaction. This can make it difficult to directly infer real-world impact.



If we want an early warning system for whether AI R&D is being accelerated by AI itself, or even automated, it would be useful to be able to directly measure this in real-world engineer trials, rather than relying on proxies like benchmarks or even noisier information like anecdotes.

So how do we reconcile our results with other sources of data on AI capabilities, like impressive benchmark results, and anecdotes/widespread adoption of AI tools?

Our RCT may underestimate capabilities for various reasons, and benchmarks and anecdotes may overestimate capabilities (likely some combination)—we discuss some possibilities in our accompanying blog post.

What do we take away?



1. It seems likely that for some important settings, recent AI tooling has not increased productivity (and may in fact decrease it).



2. Self-reports of speedup are unreliable—to understand AI’s impact on productivity, we need experiments in the wild.

Another implication:



It is sometimes proposed that we should monitor AI R&D acceleration inside of frontier AI labs via simple employee surveys. We’re now more pessimistic about these, given how large of a gap we observe between developer-estimated and observed speed-up.





1. Our setting represents all (or potentially even most) software engineering.



2. Future models won't be better (or current models can’t be used more effectively). What we're NOT saying:Our setting represents all (or potentially even most) software engineering.Future models won't be better (or current models can’t be used more effectively).





Paper:



Blog: We’re exploring running experiments like this in other settings—if you’re an open-source developer or company interested in understanding the impact of AI on your work, reach out to us here: forms.gle/pBsSo54VpmuQC4… Paper: metr.org/Early_2025_AI_… Blog: metr.org/blog/2025-07-1…

• • •

---

### The
 Origin of the Research University (38 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fasteriskmag.com%2Fissues%2F10%2Fthe-origin-of-the-research-university%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/PZM7jyqBIAsJBPgQcWK5-L8QDDxqOrgzHm6xTg5sEk8=413
**TLDR Summary:** Universities have existed for more than a thousand years, but for almost all of the time, they weren't centers of research. This article looks at what changed in 19th-century Germany that caused the birth of the research university. The real contribution of the research university is that it created a world where scholars don't have to be originals or geniuses to contribute.
**Full Article Content:**
If you were alive in 1800 and someone asked you about the future of research, it wouldn’t occur to you to mention the university. Real scholarship happened in new, modern, enlightened institutions like the British Royal Society or the French Académie des sciences. Universities were a medieval relic. And nowhere was it more medieval, hidebound, and generally dysfunctional than in the German-speaking world. But something happened to German universities at the turn of the 19th century — they developed a new system that combined teaching with research. Within a few decades, everyone in Europe was trying to copy their model. German scientists dominated chemistry and revolutionized modern physics. They came up with cell theory, bacteriology, the whole laboratory-based model of scientific medicine, and I don’t think it’s much of a stretch to say that they invented the social sciences in almost full generality. By the end of the century, they were the greatest engine of organized knowledge production the world had ever seen — and if they’ve since been surpassed by the American university system, that’s mostly because we copied them. I think we don't properly appreciate how surprising this is. It’s odd that the research university exists at all. Universities have been around for a thousand years, but for most of their history, they were not seen as institutions for producing new knowledge. It’s even stranger that it came to be in a land which was politically fragmented, lacked a strong scientific community, and had very limited interest in creating one. So I can’t help but ask: Why Germany? Why universities? Why does the entire modern institutional research ecosystem look the way it does? Does this history have anything to tell us about how to navigate an era of intense hostility and pessimism towards academia? (No promises!) Who made this thing? Were they even trying to? And why does it work so well?

Bibliotheca Büloviana Acaddemae, Georgiae Augustae donata Göttinga, engraved by Georg Daniel Heumann (1691–1759). Göttingen University Library, founded in 1734, was considered the first academic research library.

German universities in the age of Enlightenment

Scholars at early modern universities did research — but it was on their own time. Universities in early modern Europe were teaching institutions. Their primary purpose was to produce priests, lawyers, and doctors. To this end, they had four traditional faculties: theology, law, medicine, and what the Germans called philosophy. This last included everything that might be part of a modern arts and sciences education — any subject, from poetry to physics, which wasn’t directly pre-professional. Of the four, it was by far the least prestigious and worst attended. Professors were paid exclusively for lecturing, usually not very much, and professors of the arts and sciences were paid the least of all. Starting in the 16th century, these factors tended to push the people most interested in advancing human knowledge outside of universities. The trend started in astronomy. Copernicus, Brahe, and Galileo all began their careers as university professors, and all left for positions as civil servants or court astronomers which offered more money and more freedom. (Kepler, because of his heterodox approach to Lutheranism, was never able to secure a university chair at all.) Some universities tried to invest in experimental facilities — an observatory at Utrecht, a chemical laboratory at Altdorf — but these couldn’t compete with the great private or government-funded facilities being built in England and France. While many intellectuals stayed in academia, leading scholars were more and more likely to take up better offers elsewhere. The intellectual center of gravity shifted from universities to the international republic of letters. German universities in the Age of Enlightenment shared all of these problems and more. Their curriculum was, quite literally, medieval. So were their endowments. Hiring was rife with nepotism — and even when it didn’t involve replacing a professor with someone’s son or son-in-law, it was loosely related to any modern conception of academic merit. Specialization was non-existent. It hardly mattered if a professor of oriental languages could read Hebrew or Arabic, so long as he had adequate seniority, and a poetry professor who wanted a raise might well be handed an additional chair in mathematics. The students were menaces, given to drunkenness, gambling, dueling, and chronically skipping class. Everyone agreed that German universities needed to change. But very few people thought that this should involve making them centers of free intellectual inquiry. Instead, Enlightenment critics wanted them to be useful. A scholar of the 17th century might have called the university an intellectual res publica, an independent body politic. By the second half of the 18th, he was much more likely to use the word factory. Even Immanuel Kant — in an essay defending the pursuit of pure knowledge! — called universities places where scholars were gathered fabrikenmäßig: as if in a factory. At the time, this was a good thing. Factories, unlike universities, were efficient and modern. Above all, they were beneficial to the state. In the influential 1783 novel Carl von Carlsberg by education reformer Christian Gotthilf Salzmann, one character remarks to another that the university’s problems can’t be blamed on professors being incompetent (though they are), but on the impossibility of trying to adapt an institution founded in the time of the Crusades for the modern world. This was a pretty typical opinion: the structure of the university, with its odd ceremonies, independent faculties, and clerical distance from worldly affairs, was a relic — and professors, like priests, were defending the old order from necessary reform. Some radicals wanted to abolish universities altogether and replace them with specialized colleges in practical subjects. More often, reformers wanted to keep them around but break their traditional independence. An ideal university was not so different from the Royal Porcelain Manufactory, established at Berlin in 1763 — an institution using the best modern technical expertise to produce high-quality goods, whether those goods were civil servants or coffee services. This strain of enlightened university critique dovetailed neatly with the native German tradition of cameralism: the science of public administration. The cameralists who staffed 18th century German ministries of education had very clear goals for universities. They should attract rich students who would spend money in the local economy. They should produce competent civil servants, doctors, and ministers. Cameralist reforms involved finding new ways to monitor university activities, standardizing qualifications, and ending professorial nepotism — which also meant bringing those hiring decisions under much tighter state control. Often, they tried to leverage divisions within a faculty through private correspondence with a few chosen favorites — a practice actively recommended by the enlightenment journal the Berlinische Monatsschrift in 1795. Enlightenment reformers and cameralist bureaucrats didn’t agree on everything, but they were united in their desire to impose some kind of meritocratic rationale on professorial hiring. As we’ll see, they mostly failed. The rights of traditional university faculties were protected by ancient laws (and ancient lawyers). It wouldn’t be accurate to call these professors defenders of academic freedom in the modern sense, because almost everyone involved accepted state control over what could be taught. Still, they fought fiercely for the ability to make their own hiring decisions. Without the ability to place their own people, liberal intellectuals and utilitarian bureaucrats alike didn’t do much to change university culture. The exception was when states founded universities themselves. In the 1730s, George II of Britain and Hanover decided that the academic situation in his German domains was unbefitting a great power. The result was the crown jewel of 18th century German academia: the University of Göttingen. Because Göttingen was funded directly by the government instead of relying on a complicated medieval system of tithes and land rents, the state played a much stronger role in appointments. It hired famous professors and allowed them to teach non-traditional subjects like modern history or applied mathematics. It had a modern academic research library, the largest in the world, which featured brand-new innovations like organizing books on shelves by subjects with reference to a catalogue. The university also had a knight school (Ritter-Akademie) to teach subjects like riding and fencing, because that’s what got students from rich families excited, but even with the medieval flourishes, Göttingen came to define the Enlightenment university.

Göttingen and the birth of modern academia

If you’ve ever been personally victimized by the need to publish or perish, you can blame one man, and his name was Gerlach Adolph von Münchhausen. As prime minister of Hanover, Münchhausen was the sponsor of Göttingen university, and probably the single person most responsible for introducing a new criterion for academic advancement: the publication record. Münchhausen insisted that Göttingen professors write, but he was less interested in what exactly they wrote. They might produce traditional academic dissertations, but textbooks were just as good. Best of all was contributing to journals, like their own Göttinger gelehrte Anzeigen. The GGA, like most mid-18th century German publications, was somewhere between a book review journal and a collection of summaries of everything the editors considered noteworthy from the past year. It wasn’t always original, and it wasn’t trying to be. To understand why it mattered, we need to remember what Göttingen was for: training ministers and attracting rich students from other German states who would come to spend money in Hanover. (Johann David Michaelis, a famous Göttingen biblicist, once calculated the state’s expected profit per student down to the thaler.) Göttingen professors were prolific journal contributors, because journals had wide circulation, which made them famous, which helped their university attract more students. “We do not demand that we be regarded as gatekeepers of the temple of scholarly honor, and our judgment as that of the learned world,” the editors wrote in the preface to a 1744 edition of the GGA. I think that they protest too much. This was exactly what they demanded! At least, it was what they were trying to achieve. Göttingen was the cameralist university par excellence, and the currency of the cameralist university was fame. Göttingen’s reforms worked very well for their intended purpose. Wealthy students increasingly chose to study in Hanover. Prussia adopted a publication requirement for professorships in 1749 (although they still didn’t mandate that the publications be in the subject the professor was ostensibly required to teach). Today, we’re used to complaints that modern academia is fallen because promising young scholars now have to spend their time burnishing their resumes with useless publications instead of doing real research. This is precisely backwards. Promising young scholars had to burnish their resumes with useless publications long before anyone thought of asking them to do real research.

I’ll go further: all this resume-building was an important precondition for the development of an academic research culture. And it is a research culture that we should be interested in. 18th century German bureaucrats didn’t invent the idea of making new contributions to human knowledge. Their great contribution was to institutionalize it: They created a system where original scholarship was rewarded by professional advancement. This system didn’t quite exist in the 1740s. At new universities like Göttingen, academics were rewarded for what they wrote. It wasn’t yet important that this writing be research. Which raises an important question: what is research? Of course, originality is one requirement. Research should tell us something we didn’t know before. But novelty alone isn’t enough. William Clark, whose Academic Charisma is easily the best book on early modern German academia, has a wonderful list of “erudite dissertations:” treatises about academics who didn’t publish anything, or who made pacts with the devil, or had wicked wives. This was a popular microgenre. There are dozens of them. (My favorite is the one about academics who died of studying too much.) You can’t say they didn’t require original scholarship — someone had to root around in an archive — but it’s also difficult to call them research. Today, research papers are almost never plausibly-deniable high effort practical jokes. You can’t always say the same about 18th century academic writing. Again: it’s not that nobody in German universities did research. It’s that they lacked the incentives to prefer it to sterile intellectual virtuosity. The erudite dissertations aren’t just useless — research doesn’t have to be useful. For Clark, the real problem with them is that they don’t lead anywhere. They’re a way of showing off, not part of a broader scholarly dialogue. "Works of research usually provide a basis for further research and/or relate to other, related works in a complementary and supplementary manner. They add up to something positive." I like this as a definition of research. It is also very German. Specifically, I think it goes back to Immanuel Kant. Kant was very much not a cameralist. Instead, he argued that the philosophy faculty required independence — from the government as well as the "higher" faculties of law, theology, and medicine — in order to carry out its real business, pursuing truth. The suggestion that the part of the university devoted to pure knowledge might exist on equal footing with the professional schools was itself revolutionary. But Kant also had opinions on what the structured pursuit of truth should look like. "If a doctrine is a system," he wrote in his 1786 book The Metaphysical Foundations of Natural Science, “that is, a complete understanding organized according to principles, then it's called science (Wissenschaft).” In this case, he is talking about the natural sciences specifically, but the concept of Wissenschaft is much broader. The Germanists Paul Reiter and Chad Wellmon translate the word as “systematic knowledge,” which is more accurate, but in this case, it would be burying the lede: the key idea here is that it's important for knowledge to be systematic at all. What makes a discipline scientific — that is, worthy of study — is its internal order, through which disciplined, methodical investigations combine into a single, coherent whole. In other words: they add up to something. In this respect, Kant's first and best disciples were the classicists. Classical philology was the first academic field in Germany to organize itself around the idea of Wissenschaft — the collective pursuit of systematic knowledge. This development in turn grew out of yet another Göttingen institution: the seminar. The first seminar in classical philology was established at Göttingen in 1738. It was most directly inspired by Prussia’s pedagogical seminars — specialized, state-funded institutes for teacher training. Like them, it was a budgeted institution funded directly by the government. It also existed to train teachers (in this case, to teach Latin and Greek at advanced secondary schools, or Gymnasien). And for about 30 years, that’s all it did. Things changed in 1763 when the famous classicist and archeologist Christian Gottlob Heyne took over as director. Under Heyne, the philology seminar borrowed elements from other institutions, most notably collegia — private classes professors would teach to small groups of students for extra fees — and extra-curricular classics societies. (Heyne had previously taught a popular collegium on archeology.) Formal university classes were lectures, full-stop. This seminar was different. It demanded active student participation. Here’s Heyne in 1765 talking about how it worked: "The seminarists are obliged to attend several hours of collegia in the humanities each day. In addition to this, the Professor of Eloquence [Heyne] will offer without charge a collegium in which they will be practiced and instructed in interpretation, and in writing, speaking and disputing in Latin. To this end, each [seminarist] in turn will explicate, both grammatically and critically, an ancient author, as well as writing and defending an essay, written in good Latin, on a topic dealing with [philological] sciences in the same manner. "

There's a lot that's traditional here — the practice of disputation, for example, goes back to the middle ages. But there is also a lot that is new: most notably, the requirement that students produce written assignments. And not just any written assignments! Heyne's seminarists were required to present arguments for their own positions, which other students would critique and dispute. Instead of (well, in addition to) absorbing their professors’ opinions, they practiced the skills of grammatical analysis and historical source criticism which would eventually let them make their own contributions. This would become standard practice in German academia by the 19th century, but in 1763 it was entirely novel. And it proved popular. Over the next few decades, more universities established philology seminars on the Göttingen model — Wittenberg, Erlangen, Kiel, Helmsted, and Halle. Ironically, Göttingen’s most important philology student never attended Heyne’s seminar. (Heyne disapproved of his views on Homer). Still, Friedrich August Wolf managed to graduate and eventually lead his own philology seminar at the university of Halle. There, he began to develop a new approach to the study of antiquity which he would eventually lay out in his book, Darstellung der Altertumswissenschaft. His goal was nothing less than to elevate his field to “the dignity of a well-ordered philosophical-historical science.” This new science of philology was to be clear, ordered, and coherent. It would have 24 subdisciplines, ranging from grammar to numismatics. And every contribution, whether it was a seminar paper on a rare Lydian coin or a dissertation on a fragment of Archilochus, would be part of the same project: building a holistic understanding of the classical world. Wolf was deeply influenced by Kant’s understanding of Wissenschaft. (One contemporary called him the “Kant of philology.”) But that’s not surprising; everyone was influenced by Kant. There’s another reason why classical philology was the first field to truly reorganize itself on Kantian lines. Remember, this is before any kind of institutional academic specialization. The classicists were early to understand themselves as a field in the first place, and this was because of the seminar. Wolf did his best to bar theology students from attending his seminar at Halle. He wanted philology majors only, because he saw his work as training practitioners of philology. The idea of a holistic science of antiquity went hand-in-hand with giving that science its own disciplinary identity. Like everyone else, philologists had to publish or perish, and the work they published was shaped by a new sense of intellectual unity and purpose. This is the start of the era of major collective research projects — things like biographical dictionaries or catalogues of attestations which future classicists could use in their own work. (And they have. Some of this material is still cited today.) By 1800, the study of antiquity was looking a lot more modern than anything else happening in German academia. Our next question is how the ideal of Wissenschaft reached everyone else.

The Romantic turn

Let’s step back and take stock: German universities were in a state of crisis. Enrollments had dropped from 4,400 in 1720 to just under 3,000 in 1800 (while the population of the German states doubled). The reformed universities — Göttingen, and to a lesser extent Halle — had healthy student bodies, but everywhere else was struggling badly. Most had fewer than two hundred students. When the governments of the smaller German states tried to bring reforms to their own, more established universities, they still faced intense faculty opposition. The University of Jena is a typical, if unusually star-studded, case. Duke Karl August of Saxe-Weimar was a modern, enlightened ruler with a passion for acquiring famous intellectuals (at this point, Johann Wolfgang von Goethe was one of his ministers). Around 1798, he started to recruit a new crop of brilliant young scholars to his university: the playwright Friedrich Schiller, theologian Ernst Schleiermacher, philosophers Johann Gottlieb Fichte, G.W.F. Hegel, and F.W.J. Schelling, and the polymathic brothers Friedrich and August Wilhelm Schlegel. The result was a cold war between the faculty and the Weimar government: the duke couldn't impose full professors on the university, but he did have the right to appoint Extraordinarien, or extraordinary professors. Extraordinarien usually didn’t draw salaries and had to support themselves entirely on lecture fees, which depended on the number of students they could attract. Some of the duke’s new finds, like Schiller, were simply bad lecturers. Fichte was popular with students, but had to resign after being accused of atheism. Others left for more stable positions. Soon, the whole group dispersed. But the experiment wasn’t a total failure. The golden years of Jena didn’t last very long. There were four of them. But from 1798 to 1802, the town was the place to be. It was the center of post-Kantian Idealist philosophy and the birthplace of the Romantic movement in literature. The Jena circle included the young lecturers as well as poets and dramatists, drawn to Weimar by the presence of Goethe and Schiller. They wrote. They attended salons hosted by Caroline Schlegel. They lectured. And one of their favorite subjects to lecture on was the purpose of the university. Schiller, Fichte, and Schelling’s Jena lectures didn’t share a precisely identical idea of what that purpose was, but they agreed on the important points. All of them were vicious critics of what Schelling called the Enlightenment “utility gospel.” University studies weren’t about anything so crass as preparing for a profession (Schiller’s inaugural lecture is ostensibly about universal history, but he keeps breaking off into tangents about how careerist students are ruining the life of the mind). Universities existed to serve Wissenschaft. And all of them had a distinctly Romantic view of what Wissenschaft should be: not the sterile accumulation of individual facts — another Enlightenment pathology — but pursuing the true understanding of reality as a unified and organic whole. This was why, for all its faults, the university had to be preserved. It was the only institution which could spread the universal pursuit of knowledge. The specialized schools advocated by Enlightenment reformers could not serve this purpose. Nor could scientific academies, since they didn’t have students. In the Romantic worldview, the goal of education was not to memorize facts but rather to train the capacity to notice connections between them and incorporate new information into the same systematic framework. As Schelling wrote, “knowledge of the organic whole of all sciences must therefore precede a particular education focused on a single specialty.” In other words — specifically, Fichte’s — the purpose of the university was “the formation and development of the capacity to learn.” Of all these men, I think Fichte had the best understanding of how Romantic educational ideas would work in practice. His central idea was that universities should foster personal self-development (Bildung) as thinkers and scholars, but also as moral beings. In fact, these were the same thing. Through a carefully constructed program of seminars and socratic dialogues, students would be encouraged to cultivate the faculty of scholarly reason which would guide them through the world as fully-realized individuals. The capacity to learn would serve students far beyond their university days. It was the same capacity that would allow them to discover new things about the world. Fichte’s friend Schleiermacher, the theologian, who shared many of his opinions, framed the same statement slightly differently. The university, he wrote, “forms the transition between the time when a young man is first prepared for systematic knowledge, by his own studying and by acquiring a knowledge base, and the time when, in the prime of his in­tellectual life, he expands the field or adds on a beautiful new wing to the edi­fice of knowledge through his own research.” Schleiermacher didn’t want universities to be centers of research production. He still thought academies of science would serve that role. Still, for the Romantics, research was an essential part of being a professor — not because of their outputs, but because it was the only way they could model holistic intellectual inquiry for their students. The professor's job was to embody endless curiosity and dedication to the systematic pursuit of pure knowledge, which was, after all, man's highest calling.

Berlin, and beyond

This all sounds very nice. Probably none of it would ever have been implemented if not for a fortunate turn of events: the humiliating subjugation of Prussia by Napoleon Bonaparte. In the short term, the Napoleonic wars killed off the old university system. Within a few years, half of all German universities shut down. Halle, the centerpiece of Prussian academia, closed in 1806. After Prussia made peace with France, there was widespread agreement that they would have to build something to replace it — but it was not at all clear what, or if it would even take the form of a university. In the end, it did, mostly thanks to another man — the linguist, liberal philosopher, and (briefly) education bureaucrat Wilhelm von Humboldt. Humboldt didn't shape the public debate around the role of the university in the early years of the 19th century. What he did was synthesize it. In his short tenure as a Prussian educational administrator, from 1809 to 1810, he developed a plan for an institution to be built in Berlin, modeled on the pedagogical vision of Schelling, Fichte, and Schleiermacher, but also inspired by his own alma mater, Göttingen. Today, Humboldt gets a lot of credit for the core values of German academia: the unity of teaching and research, the freedom to teach or study whatever you choose, the primacy of the philosophy faculty and its dedication to pure knowledge. As we’ve seen, he didn’t come up with any of these ideas, but he did play a key role in giving them an institutional home. There were also less Idealistic motives at play. Napoleon's invasion had sparked a backlash to all things French, and there was nothing more French than abolishing crippled medieval institutions and replacing them with modern, utilitarian ones. France had already abolished its own universities and replaced them with specialized schools for training civil servants, so Prussia was determined to keep them. It also helped that building a university in Berlin was cheap. Most German universities at this time weren't built in large cities, out of concerns that urban life would be distracting to the students (or that the students would be hazardous to the townsfolk). But Berlin already had an academy of sciences, whose members could be enlisted as professors, a royal library, which could be appropriated, and a hospital — Charité — which could serve as a medical school. In May 1809, Humboldt wrote a letter to the king requesting the establishment of this new university. This document spends less time on the value of academic freedom than it does on the advantages to the state: the cost savings from locating the university in Berlin, the necessity of restoring national pride after years of war, the boost to Friedrich Wilhelm's own reputation. It also gives you a sense of the political uphill battle the very concept of the university was facing: “Even the name ‘university,’ if I may say so, will not require me to offer an excuse to Your Majesty. It is meant simply to signify that no field of knowledge is excluded, and that the teaching institution will also grant academic titles. Everything else about the university that is antiquated or detrimental will, of course, be avoided.” The university of Berlin was founded in 1810. How radical was it in practice? Formally, it looked a lot like Göttingen: it had the same academic ranks, the same financial model, and the same four faculties — though with philosophy elevated to a more central intellectual role. Fichte, the most radical of the reformers, left in 1812, while the more accommodating Schleiermacher remained. Humboldt's own replacement as minister was a traditional bureaucrat in the enlightened-cameralist mode. And for all the talk about the primacy of pure knowledge, students in the career-oriented law, theology, and medical faculties still outnumbered the philosophers. Students who cared about education for its own sake might have been a minority, as they have been at every university everywhere approximately always. Still, the best of them flocked to Berlin. In addition to the famous professors, they were drawn in by important pedagogical innovations. There were no compulsory classes or compulsory assignments. Students were only examined at the end of their studies, leaving them free to construct whatever curriculum they liked. Most intellectual work happened in seminars, which proliferated. I think there was another inducement here, too: Romanticism made studying — for lack of a better word — romantic. The dominant cultural image of the university student before the Jena circle got to it was a particularly vicious frat boy. (Which was accurate. Fraternity violence was a significant social problem.) After Jena, you start to see a lot more paeans to the life of the mind. It’s hard to disentangle the structural changes in university policy from the broader cultural impact of Romanticism, but here, they come together. Berlin was an exciting place to study, but a generation of students who grew up reading Schiller or Novalis were just more excited about scholarship. One important structural change was the Berlin Ph.D. Partly, it was that they had one at all: the idea that the “lower” faculty of philosophy could grant doctorates was highly controversial. As university rector, Fichte not only insisted on offering the degree, but added two novel requirements: candidates needed to write their own dissertations — and they needed to be works of original research. This was a very big change. Like seminars, dissertations have their roots in the medieval disputation. Starting in the 16th century, German doctoral candidates would hold a disputation as part of their graduation ceremony. In these disputations, they would defend a set of theses — written by the presiding professor. Professors would produce tens of thousands of these — before journals were common, they were the predominant form of academic publication. However, they typically weren’t new contributions to human knowledge. The dissertation was a test of a candidate's ability to defend their mentor's work. The work itself didn’t have to be new. It wasn’t unusual for professors to recycle the same dissertations for multiple defenses, and the contents might as easily reflect Aristotle or Melanchthon as their own studies. It is not a coincidence that almost every single doctorate granted by the university of Berlin in its early years was in the field of classical philology. Fichte’s conception of the PhD was a natural extension of the Romantic view of the university: If the university existed to train researchers, then naturally a student’s education should culminate in proof of their ability to produce research. But in 1810, the only field with an established practice of training students to do original work was classics. Slowly, the ideal of scientific education developed in classics seminars spread to the natural and social sciences. Fields from anthropology to zoology got their own seminars or institutes. As it had in classics, this led to the birth of new disciplinary identities. Through the 1820s, this curricular expansion spread to other universities — Münich, Giessen, Kiel, Göttingen, and Heidelberg. Scientific research was migrating back into academia. This led to a problem the Romantics had not anticipated: specialization. The ideal of Wissenschaft had encouraged academics to build up institutions to train future generations of scholars. But, naturally and inevitably, these networks of seminars and institutes acculturated students into the research practices of particular fields of study. The ideal of the unity of all knowledge got lost very early on in this process, if it ever took hold to begin with. Another area where the Romantics lost out was academic publishing. This was an Enlightenment thing and they resented it. Their ideal university culture was oral/aural: true Bildung happened in lectures or seminar discussions where students and teachers could learn together directly. Schleiermacher was even opposed to writing down lecture notes in advance, since this would get in the way of the students “directly observing the activity of intelligence producing knowledge.” The real, lasting contribution of Romanticism was to make originality and the pursuit of knowledge a source of academic status — but this directly contributed to an explosion of writing. Young scholars wanted to show their devotion to Wissenschaft. Meanwhile, 19th century academia was getting much more competitive. Extraordinarien and the even lowlier Privatdozenten had always outnumbered full professors, but now the ratios started to become extreme. There were ever more candidates for every chair, which led faculties and educational ministries to raise their standards for full professorships, which meant requiring even more publications. This research ratchet was helped along by a new generation of Prussian bureaucrats. Johannes Schulze, a key Prussian educational administrator — and admirer of Wolf's seminar at Halle — instituted research stipends for young professors and prizes for original student work. Administrators also came to value research as a professional qualification. By midcentury, the culture of German universities looked a lot like that of modern academia. Professors split their time between research and teaching duties, but found research ever more relevant for their own professional advancement. They considered themselves members of distinct fields with their own practices and methods. They published in specialized journals. They wrote their own dissertations, which contained original contributions to human knowledge. Everyone agreed that there were way too many adjuncts. Every university in the world today has incorporated at least some element of this model. States like Russia and Greece, without strong university systems of their own, were quickest to adopt it. The French educational reformer Victor Cousin was an admirer of Kant and Fichte and pushed for some German-style reforms, if not the same institutional support for research. (As late as 1868, Louis Pasteur was doing experiments in his attic). Of course, nobody took to the German university ideal more eagerly than the Americans. The founders of Johns Hopkins and the University of Chicago were explicitly built on German models. Charles Eliot, the president of Harvard from 1869 to 1909, was a committed Germanophile, and reformed Harvard’s graduate school along German lines. The whole institutional structure of American graduate education is German, from academic departments (an outgrowth of the seminar) to doctoral dissertations. It’s Humboldt’s world, and we’re just living in it.

What have we learned?

---

### The
 Origin of the Research University (38 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fasteriskmag.com%2Fissues%2F10%2Fthe-origin-of-the-research-university%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/PZM7jyqBIAsJBPgQcWK5-L8QDDxqOrgzHm6xTg5sEk8=413
**TLDR Summary:** Universities have existed for more than a thousand years, but for almost all of the time, they weren't centers of research. This article looks at what changed in 19th-century Germany that caused the birth of the research university. The real contribution of the research university is that it created a world where scholars don't have to be originals or geniuses to contribute.
**Full Article Content:**
If you were alive in 1800 and someone asked you about the future of research, it wouldn’t occur to you to mention the university. Real scholarship happened in new, modern, enlightened institutions like the British Royal Society or the French Académie des sciences. Universities were a medieval relic. And nowhere was it more medieval, hidebound, and generally dysfunctional than in the German-speaking world. But something happened to German universities at the turn of the 19th century — they developed a new system that combined teaching with research. Within a few decades, everyone in Europe was trying to copy their model. German scientists dominated chemistry and revolutionized modern physics. They came up with cell theory, bacteriology, the whole laboratory-based model of scientific medicine, and I don’t think it’s much of a stretch to say that they invented the social sciences in almost full generality. By the end of the century, they were the greatest engine of organized knowledge production the world had ever seen — and if they’ve since been surpassed by the American university system, that’s mostly because we copied them. I think we don't properly appreciate how surprising this is. It’s odd that the research university exists at all. Universities have been around for a thousand years, but for most of their history, they were not seen as institutions for producing new knowledge. It’s even stranger that it came to be in a land which was politically fragmented, lacked a strong scientific community, and had very limited interest in creating one. So I can’t help but ask: Why Germany? Why universities? Why does the entire modern institutional research ecosystem look the way it does? Does this history have anything to tell us about how to navigate an era of intense hostility and pessimism towards academia? (No promises!) Who made this thing? Were they even trying to? And why does it work so well?

Bibliotheca Büloviana Acaddemae, Georgiae Augustae donata Göttinga, engraved by Georg Daniel Heumann (1691–1759). Göttingen University Library, founded in 1734, was considered the first academic research library.

German universities in the age of Enlightenment

Scholars at early modern universities did research — but it was on their own time. Universities in early modern Europe were teaching institutions. Their primary purpose was to produce priests, lawyers, and doctors. To this end, they had four traditional faculties: theology, law, medicine, and what the Germans called philosophy. This last included everything that might be part of a modern arts and sciences education — any subject, from poetry to physics, which wasn’t directly pre-professional. Of the four, it was by far the least prestigious and worst attended. Professors were paid exclusively for lecturing, usually not very much, and professors of the arts and sciences were paid the least of all. Starting in the 16th century, these factors tended to push the people most interested in advancing human knowledge outside of universities. The trend started in astronomy. Copernicus, Brahe, and Galileo all began their careers as university professors, and all left for positions as civil servants or court astronomers which offered more money and more freedom. (Kepler, because of his heterodox approach to Lutheranism, was never able to secure a university chair at all.) Some universities tried to invest in experimental facilities — an observatory at Utrecht, a chemical laboratory at Altdorf — but these couldn’t compete with the great private or government-funded facilities being built in England and France. While many intellectuals stayed in academia, leading scholars were more and more likely to take up better offers elsewhere. The intellectual center of gravity shifted from universities to the international republic of letters. German universities in the Age of Enlightenment shared all of these problems and more. Their curriculum was, quite literally, medieval. So were their endowments. Hiring was rife with nepotism — and even when it didn’t involve replacing a professor with someone’s son or son-in-law, it was loosely related to any modern conception of academic merit. Specialization was non-existent. It hardly mattered if a professor of oriental languages could read Hebrew or Arabic, so long as he had adequate seniority, and a poetry professor who wanted a raise might well be handed an additional chair in mathematics. The students were menaces, given to drunkenness, gambling, dueling, and chronically skipping class. Everyone agreed that German universities needed to change. But very few people thought that this should involve making them centers of free intellectual inquiry. Instead, Enlightenment critics wanted them to be useful. A scholar of the 17th century might have called the university an intellectual res publica, an independent body politic. By the second half of the 18th, he was much more likely to use the word factory. Even Immanuel Kant — in an essay defending the pursuit of pure knowledge! — called universities places where scholars were gathered fabrikenmäßig: as if in a factory. At the time, this was a good thing. Factories, unlike universities, were efficient and modern. Above all, they were beneficial to the state. In the influential 1783 novel Carl von Carlsberg by education reformer Christian Gotthilf Salzmann, one character remarks to another that the university’s problems can’t be blamed on professors being incompetent (though they are), but on the impossibility of trying to adapt an institution founded in the time of the Crusades for the modern world. This was a pretty typical opinion: the structure of the university, with its odd ceremonies, independent faculties, and clerical distance from worldly affairs, was a relic — and professors, like priests, were defending the old order from necessary reform. Some radicals wanted to abolish universities altogether and replace them with specialized colleges in practical subjects. More often, reformers wanted to keep them around but break their traditional independence. An ideal university was not so different from the Royal Porcelain Manufactory, established at Berlin in 1763 — an institution using the best modern technical expertise to produce high-quality goods, whether those goods were civil servants or coffee services. This strain of enlightened university critique dovetailed neatly with the native German tradition of cameralism: the science of public administration. The cameralists who staffed 18th century German ministries of education had very clear goals for universities. They should attract rich students who would spend money in the local economy. They should produce competent civil servants, doctors, and ministers. Cameralist reforms involved finding new ways to monitor university activities, standardizing qualifications, and ending professorial nepotism — which also meant bringing those hiring decisions under much tighter state control. Often, they tried to leverage divisions within a faculty through private correspondence with a few chosen favorites — a practice actively recommended by the enlightenment journal the Berlinische Monatsschrift in 1795. Enlightenment reformers and cameralist bureaucrats didn’t agree on everything, but they were united in their desire to impose some kind of meritocratic rationale on professorial hiring. As we’ll see, they mostly failed. The rights of traditional university faculties were protected by ancient laws (and ancient lawyers). It wouldn’t be accurate to call these professors defenders of academic freedom in the modern sense, because almost everyone involved accepted state control over what could be taught. Still, they fought fiercely for the ability to make their own hiring decisions. Without the ability to place their own people, liberal intellectuals and utilitarian bureaucrats alike didn’t do much to change university culture. The exception was when states founded universities themselves. In the 1730s, George II of Britain and Hanover decided that the academic situation in his German domains was unbefitting a great power. The result was the crown jewel of 18th century German academia: the University of Göttingen. Because Göttingen was funded directly by the government instead of relying on a complicated medieval system of tithes and land rents, the state played a much stronger role in appointments. It hired famous professors and allowed them to teach non-traditional subjects like modern history or applied mathematics. It had a modern academic research library, the largest in the world, which featured brand-new innovations like organizing books on shelves by subjects with reference to a catalogue. The university also had a knight school (Ritter-Akademie) to teach subjects like riding and fencing, because that’s what got students from rich families excited, but even with the medieval flourishes, Göttingen came to define the Enlightenment university.

Göttingen and the birth of modern academia

If you’ve ever been personally victimized by the need to publish or perish, you can blame one man, and his name was Gerlach Adolph von Münchhausen. As prime minister of Hanover, Münchhausen was the sponsor of Göttingen university, and probably the single person most responsible for introducing a new criterion for academic advancement: the publication record. Münchhausen insisted that Göttingen professors write, but he was less interested in what exactly they wrote. They might produce traditional academic dissertations, but textbooks were just as good. Best of all was contributing to journals, like their own Göttinger gelehrte Anzeigen. The GGA, like most mid-18th century German publications, was somewhere between a book review journal and a collection of summaries of everything the editors considered noteworthy from the past year. It wasn’t always original, and it wasn’t trying to be. To understand why it mattered, we need to remember what Göttingen was for: training ministers and attracting rich students from other German states who would come to spend money in Hanover. (Johann David Michaelis, a famous Göttingen biblicist, once calculated the state’s expected profit per student down to the thaler.) Göttingen professors were prolific journal contributors, because journals had wide circulation, which made them famous, which helped their university attract more students. “We do not demand that we be regarded as gatekeepers of the temple of scholarly honor, and our judgment as that of the learned world,” the editors wrote in the preface to a 1744 edition of the GGA. I think that they protest too much. This was exactly what they demanded! At least, it was what they were trying to achieve. Göttingen was the cameralist university par excellence, and the currency of the cameralist university was fame. Göttingen’s reforms worked very well for their intended purpose. Wealthy students increasingly chose to study in Hanover. Prussia adopted a publication requirement for professorships in 1749 (although they still didn’t mandate that the publications be in the subject the professor was ostensibly required to teach). Today, we’re used to complaints that modern academia is fallen because promising young scholars now have to spend their time burnishing their resumes with useless publications instead of doing real research. This is precisely backwards. Promising young scholars had to burnish their resumes with useless publications long before anyone thought of asking them to do real research.

I’ll go further: all this resume-building was an important precondition for the development of an academic research culture. And it is a research culture that we should be interested in. 18th century German bureaucrats didn’t invent the idea of making new contributions to human knowledge. Their great contribution was to institutionalize it: They created a system where original scholarship was rewarded by professional advancement. This system didn’t quite exist in the 1740s. At new universities like Göttingen, academics were rewarded for what they wrote. It wasn’t yet important that this writing be research. Which raises an important question: what is research? Of course, originality is one requirement. Research should tell us something we didn’t know before. But novelty alone isn’t enough. William Clark, whose Academic Charisma is easily the best book on early modern German academia, has a wonderful list of “erudite dissertations:” treatises about academics who didn’t publish anything, or who made pacts with the devil, or had wicked wives. This was a popular microgenre. There are dozens of them. (My favorite is the one about academics who died of studying too much.) You can’t say they didn’t require original scholarship — someone had to root around in an archive — but it’s also difficult to call them research. Today, research papers are almost never plausibly-deniable high effort practical jokes. You can’t always say the same about 18th century academic writing. Again: it’s not that nobody in German universities did research. It’s that they lacked the incentives to prefer it to sterile intellectual virtuosity. The erudite dissertations aren’t just useless — research doesn’t have to be useful. For Clark, the real problem with them is that they don’t lead anywhere. They’re a way of showing off, not part of a broader scholarly dialogue. "Works of research usually provide a basis for further research and/or relate to other, related works in a complementary and supplementary manner. They add up to something positive." I like this as a definition of research. It is also very German. Specifically, I think it goes back to Immanuel Kant. Kant was very much not a cameralist. Instead, he argued that the philosophy faculty required independence — from the government as well as the "higher" faculties of law, theology, and medicine — in order to carry out its real business, pursuing truth. The suggestion that the part of the university devoted to pure knowledge might exist on equal footing with the professional schools was itself revolutionary. But Kant also had opinions on what the structured pursuit of truth should look like. "If a doctrine is a system," he wrote in his 1786 book The Metaphysical Foundations of Natural Science, “that is, a complete understanding organized according to principles, then it's called science (Wissenschaft).” In this case, he is talking about the natural sciences specifically, but the concept of Wissenschaft is much broader. The Germanists Paul Reiter and Chad Wellmon translate the word as “systematic knowledge,” which is more accurate, but in this case, it would be burying the lede: the key idea here is that it's important for knowledge to be systematic at all. What makes a discipline scientific — that is, worthy of study — is its internal order, through which disciplined, methodical investigations combine into a single, coherent whole. In other words: they add up to something. In this respect, Kant's first and best disciples were the classicists. Classical philology was the first academic field in Germany to organize itself around the idea of Wissenschaft — the collective pursuit of systematic knowledge. This development in turn grew out of yet another Göttingen institution: the seminar. The first seminar in classical philology was established at Göttingen in 1738. It was most directly inspired by Prussia’s pedagogical seminars — specialized, state-funded institutes for teacher training. Like them, it was a budgeted institution funded directly by the government. It also existed to train teachers (in this case, to teach Latin and Greek at advanced secondary schools, or Gymnasien). And for about 30 years, that’s all it did. Things changed in 1763 when the famous classicist and archeologist Christian Gottlob Heyne took over as director. Under Heyne, the philology seminar borrowed elements from other institutions, most notably collegia — private classes professors would teach to small groups of students for extra fees — and extra-curricular classics societies. (Heyne had previously taught a popular collegium on archeology.) Formal university classes were lectures, full-stop. This seminar was different. It demanded active student participation. Here’s Heyne in 1765 talking about how it worked: "The seminarists are obliged to attend several hours of collegia in the humanities each day. In addition to this, the Professor of Eloquence [Heyne] will offer without charge a collegium in which they will be practiced and instructed in interpretation, and in writing, speaking and disputing in Latin. To this end, each [seminarist] in turn will explicate, both grammatically and critically, an ancient author, as well as writing and defending an essay, written in good Latin, on a topic dealing with [philological] sciences in the same manner. "

There's a lot that's traditional here — the practice of disputation, for example, goes back to the middle ages. But there is also a lot that is new: most notably, the requirement that students produce written assignments. And not just any written assignments! Heyne's seminarists were required to present arguments for their own positions, which other students would critique and dispute. Instead of (well, in addition to) absorbing their professors’ opinions, they practiced the skills of grammatical analysis and historical source criticism which would eventually let them make their own contributions. This would become standard practice in German academia by the 19th century, but in 1763 it was entirely novel. And it proved popular. Over the next few decades, more universities established philology seminars on the Göttingen model — Wittenberg, Erlangen, Kiel, Helmsted, and Halle. Ironically, Göttingen’s most important philology student never attended Heyne’s seminar. (Heyne disapproved of his views on Homer). Still, Friedrich August Wolf managed to graduate and eventually lead his own philology seminar at the university of Halle. There, he began to develop a new approach to the study of antiquity which he would eventually lay out in his book, Darstellung der Altertumswissenschaft. His goal was nothing less than to elevate his field to “the dignity of a well-ordered philosophical-historical science.” This new science of philology was to be clear, ordered, and coherent. It would have 24 subdisciplines, ranging from grammar to numismatics. And every contribution, whether it was a seminar paper on a rare Lydian coin or a dissertation on a fragment of Archilochus, would be part of the same project: building a holistic understanding of the classical world. Wolf was deeply influenced by Kant’s understanding of Wissenschaft. (One contemporary called him the “Kant of philology.”) But that’s not surprising; everyone was influenced by Kant. There’s another reason why classical philology was the first field to truly reorganize itself on Kantian lines. Remember, this is before any kind of institutional academic specialization. The classicists were early to understand themselves as a field in the first place, and this was because of the seminar. Wolf did his best to bar theology students from attending his seminar at Halle. He wanted philology majors only, because he saw his work as training practitioners of philology. The idea of a holistic science of antiquity went hand-in-hand with giving that science its own disciplinary identity. Like everyone else, philologists had to publish or perish, and the work they published was shaped by a new sense of intellectual unity and purpose. This is the start of the era of major collective research projects — things like biographical dictionaries or catalogues of attestations which future classicists could use in their own work. (And they have. Some of this material is still cited today.) By 1800, the study of antiquity was looking a lot more modern than anything else happening in German academia. Our next question is how the ideal of Wissenschaft reached everyone else.

The Romantic turn

Let’s step back and take stock: German universities were in a state of crisis. Enrollments had dropped from 4,400 in 1720 to just under 3,000 in 1800 (while the population of the German states doubled). The reformed universities — Göttingen, and to a lesser extent Halle — had healthy student bodies, but everywhere else was struggling badly. Most had fewer than two hundred students. When the governments of the smaller German states tried to bring reforms to their own, more established universities, they still faced intense faculty opposition. The University of Jena is a typical, if unusually star-studded, case. Duke Karl August of Saxe-Weimar was a modern, enlightened ruler with a passion for acquiring famous intellectuals (at this point, Johann Wolfgang von Goethe was one of his ministers). Around 1798, he started to recruit a new crop of brilliant young scholars to his university: the playwright Friedrich Schiller, theologian Ernst Schleiermacher, philosophers Johann Gottlieb Fichte, G.W.F. Hegel, and F.W.J. Schelling, and the polymathic brothers Friedrich and August Wilhelm Schlegel. The result was a cold war between the faculty and the Weimar government: the duke couldn't impose full professors on the university, but he did have the right to appoint Extraordinarien, or extraordinary professors. Extraordinarien usually didn’t draw salaries and had to support themselves entirely on lecture fees, which depended on the number of students they could attract. Some of the duke’s new finds, like Schiller, were simply bad lecturers. Fichte was popular with students, but had to resign after being accused of atheism. Others left for more stable positions. Soon, the whole group dispersed. But the experiment wasn’t a total failure. The golden years of Jena didn’t last very long. There were four of them. But from 1798 to 1802, the town was the place to be. It was the center of post-Kantian Idealist philosophy and the birthplace of the Romantic movement in literature. The Jena circle included the young lecturers as well as poets and dramatists, drawn to Weimar by the presence of Goethe and Schiller. They wrote. They attended salons hosted by Caroline Schlegel. They lectured. And one of their favorite subjects to lecture on was the purpose of the university. Schiller, Fichte, and Schelling’s Jena lectures didn’t share a precisely identical idea of what that purpose was, but they agreed on the important points. All of them were vicious critics of what Schelling called the Enlightenment “utility gospel.” University studies weren’t about anything so crass as preparing for a profession (Schiller’s inaugural lecture is ostensibly about universal history, but he keeps breaking off into tangents about how careerist students are ruining the life of the mind). Universities existed to serve Wissenschaft. And all of them had a distinctly Romantic view of what Wissenschaft should be: not the sterile accumulation of individual facts — another Enlightenment pathology — but pursuing the true understanding of reality as a unified and organic whole. This was why, for all its faults, the university had to be preserved. It was the only institution which could spread the universal pursuit of knowledge. The specialized schools advocated by Enlightenment reformers could not serve this purpose. Nor could scientific academies, since they didn’t have students. In the Romantic worldview, the goal of education was not to memorize facts but rather to train the capacity to notice connections between them and incorporate new information into the same systematic framework. As Schelling wrote, “knowledge of the organic whole of all sciences must therefore precede a particular education focused on a single specialty.” In other words — specifically, Fichte’s — the purpose of the university was “the formation and development of the capacity to learn.” Of all these men, I think Fichte had the best understanding of how Romantic educational ideas would work in practice. His central idea was that universities should foster personal self-development (Bildung) as thinkers and scholars, but also as moral beings. In fact, these were the same thing. Through a carefully constructed program of seminars and socratic dialogues, students would be encouraged to cultivate the faculty of scholarly reason which would guide them through the world as fully-realized individuals. The capacity to learn would serve students far beyond their university days. It was the same capacity that would allow them to discover new things about the world. Fichte’s friend Schleiermacher, the theologian, who shared many of his opinions, framed the same statement slightly differently. The university, he wrote, “forms the transition between the time when a young man is first prepared for systematic knowledge, by his own studying and by acquiring a knowledge base, and the time when, in the prime of his in­tellectual life, he expands the field or adds on a beautiful new wing to the edi­fice of knowledge through his own research.” Schleiermacher didn’t want universities to be centers of research production. He still thought academies of science would serve that role. Still, for the Romantics, research was an essential part of being a professor — not because of their outputs, but because it was the only way they could model holistic intellectual inquiry for their students. The professor's job was to embody endless curiosity and dedication to the systematic pursuit of pure knowledge, which was, after all, man's highest calling.

Berlin, and beyond

This all sounds very nice. Probably none of it would ever have been implemented if not for a fortunate turn of events: the humiliating subjugation of Prussia by Napoleon Bonaparte. In the short term, the Napoleonic wars killed off the old university system. Within a few years, half of all German universities shut down. Halle, the centerpiece of Prussian academia, closed in 1806. After Prussia made peace with France, there was widespread agreement that they would have to build something to replace it — but it was not at all clear what, or if it would even take the form of a university. In the end, it did, mostly thanks to another man — the linguist, liberal philosopher, and (briefly) education bureaucrat Wilhelm von Humboldt. Humboldt didn't shape the public debate around the role of the university in the early years of the 19th century. What he did was synthesize it. In his short tenure as a Prussian educational administrator, from 1809 to 1810, he developed a plan for an institution to be built in Berlin, modeled on the pedagogical vision of Schelling, Fichte, and Schleiermacher, but also inspired by his own alma mater, Göttingen. Today, Humboldt gets a lot of credit for the core values of German academia: the unity of teaching and research, the freedom to teach or study whatever you choose, the primacy of the philosophy faculty and its dedication to pure knowledge. As we’ve seen, he didn’t come up with any of these ideas, but he did play a key role in giving them an institutional home. There were also less Idealistic motives at play. Napoleon's invasion had sparked a backlash to all things French, and there was nothing more French than abolishing crippled medieval institutions and replacing them with modern, utilitarian ones. France had already abolished its own universities and replaced them with specialized schools for training civil servants, so Prussia was determined to keep them. It also helped that building a university in Berlin was cheap. Most German universities at this time weren't built in large cities, out of concerns that urban life would be distracting to the students (or that the students would be hazardous to the townsfolk). But Berlin already had an academy of sciences, whose members could be enlisted as professors, a royal library, which could be appropriated, and a hospital — Charité — which could serve as a medical school. In May 1809, Humboldt wrote a letter to the king requesting the establishment of this new university. This document spends less time on the value of academic freedom than it does on the advantages to the state: the cost savings from locating the university in Berlin, the necessity of restoring national pride after years of war, the boost to Friedrich Wilhelm's own reputation. It also gives you a sense of the political uphill battle the very concept of the university was facing: “Even the name ‘university,’ if I may say so, will not require me to offer an excuse to Your Majesty. It is meant simply to signify that no field of knowledge is excluded, and that the teaching institution will also grant academic titles. Everything else about the university that is antiquated or detrimental will, of course, be avoided.” The university of Berlin was founded in 1810. How radical was it in practice? Formally, it looked a lot like Göttingen: it had the same academic ranks, the same financial model, and the same four faculties — though with philosophy elevated to a more central intellectual role. Fichte, the most radical of the reformers, left in 1812, while the more accommodating Schleiermacher remained. Humboldt's own replacement as minister was a traditional bureaucrat in the enlightened-cameralist mode. And for all the talk about the primacy of pure knowledge, students in the career-oriented law, theology, and medical faculties still outnumbered the philosophers. Students who cared about education for its own sake might have been a minority, as they have been at every university everywhere approximately always. Still, the best of them flocked to Berlin. In addition to the famous professors, they were drawn in by important pedagogical innovations. There were no compulsory classes or compulsory assignments. Students were only examined at the end of their studies, leaving them free to construct whatever curriculum they liked. Most intellectual work happened in seminars, which proliferated. I think there was another inducement here, too: Romanticism made studying — for lack of a better word — romantic. The dominant cultural image of the university student before the Jena circle got to it was a particularly vicious frat boy. (Which was accurate. Fraternity violence was a significant social problem.) After Jena, you start to see a lot more paeans to the life of the mind. It’s hard to disentangle the structural changes in university policy from the broader cultural impact of Romanticism, but here, they come together. Berlin was an exciting place to study, but a generation of students who grew up reading Schiller or Novalis were just more excited about scholarship. One important structural change was the Berlin Ph.D. Partly, it was that they had one at all: the idea that the “lower” faculty of philosophy could grant doctorates was highly controversial. As university rector, Fichte not only insisted on offering the degree, but added two novel requirements: candidates needed to write their own dissertations — and they needed to be works of original research. This was a very big change. Like seminars, dissertations have their roots in the medieval disputation. Starting in the 16th century, German doctoral candidates would hold a disputation as part of their graduation ceremony. In these disputations, they would defend a set of theses — written by the presiding professor. Professors would produce tens of thousands of these — before journals were common, they were the predominant form of academic publication. However, they typically weren’t new contributions to human knowledge. The dissertation was a test of a candidate's ability to defend their mentor's work. The work itself didn’t have to be new. It wasn’t unusual for professors to recycle the same dissertations for multiple defenses, and the contents might as easily reflect Aristotle or Melanchthon as their own studies. It is not a coincidence that almost every single doctorate granted by the university of Berlin in its early years was in the field of classical philology. Fichte’s conception of the PhD was a natural extension of the Romantic view of the university: If the university existed to train researchers, then naturally a student’s education should culminate in proof of their ability to produce research. But in 1810, the only field with an established practice of training students to do original work was classics. Slowly, the ideal of scientific education developed in classics seminars spread to the natural and social sciences. Fields from anthropology to zoology got their own seminars or institutes. As it had in classics, this led to the birth of new disciplinary identities. Through the 1820s, this curricular expansion spread to other universities — Münich, Giessen, Kiel, Göttingen, and Heidelberg. Scientific research was migrating back into academia. This led to a problem the Romantics had not anticipated: specialization. The ideal of Wissenschaft had encouraged academics to build up institutions to train future generations of scholars. But, naturally and inevitably, these networks of seminars and institutes acculturated students into the research practices of particular fields of study. The ideal of the unity of all knowledge got lost very early on in this process, if it ever took hold to begin with. Another area where the Romantics lost out was academic publishing. This was an Enlightenment thing and they resented it. Their ideal university culture was oral/aural: true Bildung happened in lectures or seminar discussions where students and teachers could learn together directly. Schleiermacher was even opposed to writing down lecture notes in advance, since this would get in the way of the students “directly observing the activity of intelligence producing knowledge.” The real, lasting contribution of Romanticism was to make originality and the pursuit of knowledge a source of academic status — but this directly contributed to an explosion of writing. Young scholars wanted to show their devotion to Wissenschaft. Meanwhile, 19th century academia was getting much more competitive. Extraordinarien and the even lowlier Privatdozenten had always outnumbered full professors, but now the ratios started to become extreme. There were ever more candidates for every chair, which led faculties and educational ministries to raise their standards for full professorships, which meant requiring even more publications. This research ratchet was helped along by a new generation of Prussian bureaucrats. Johannes Schulze, a key Prussian educational administrator — and admirer of Wolf's seminar at Halle — instituted research stipends for young professors and prizes for original student work. Administrators also came to value research as a professional qualification. By midcentury, the culture of German universities looked a lot like that of modern academia. Professors split their time between research and teaching duties, but found research ever more relevant for their own professional advancement. They considered themselves members of distinct fields with their own practices and methods. They published in specialized journals. They wrote their own dissertations, which contained original contributions to human knowledge. Everyone agreed that there were way too many adjuncts. Every university in the world today has incorporated at least some element of this model. States like Russia and Greece, without strong university systems of their own, were quickest to adopt it. The French educational reformer Victor Cousin was an admirer of Kant and Fichte and pushed for some German-style reforms, if not the same institutional support for research. (As late as 1868, Louis Pasteur was doing experiments in his attic). Of course, nobody took to the German university ideal more eagerly than the Americans. The founders of Johns Hopkins and the University of Chicago were explicitly built on German models. Charles Eliot, the president of Harvard from 1869 to 1909, was a committed Germanophile, and reformed Harvard’s graduate school along German lines. The whole institutional structure of American graduate education is German, from academic departments (an outgrowth of the seminar) to doctoral dissertations. It’s Humboldt’s world, and we’re just living in it.

What have we learned?

---

### 5
 things I learned from 5 years at Vercel (10 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fleerob.com%2Fvercel%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/jB2PPtkgPHXi5OYOMeySCKJsQCZ_a2mwKs2DvIC8gf4=413
**TLDR Summary:** Lee Robinson joined Vercel in 2020 when the company had 30 people. Five years later, the company has 650 employees and over $200 million ARR. During Robinson's time at the company, he went from IC to VP and worked on DevRel, product, community, docs, and more. This post contains some of the lessons Robinson learned and how he grew as a leader and manager.
**Full Article Content:**
5 things I learned from 5 years at Vercel

july 2025 – lee robinson

After five years at Vercel, I just finished my last week. What a ride!

When I joined in 2020, we were 30 people and had crossed $1M ARR. Today, Vercel is 650 people and over $200M ARR. During that time, I went from IC to VP and worked on DevRel, product, community, docs, and more.

Here are some of the lessons I learned and how I grew as a leader and manager, as well as a bunch of behind-the-scenes photos.

Next.js Conf 2024 Vercel team dinner Japan community meetup Stanford hackathon Lydia/Delba keynote

1. Go hard at work, then go home

I responded to a Next.js tweet while sitting on the beach during my honeymoon.

That probably sounds insane. Actually yeah, it is.

Vercel was the first startup I worked at. Before Vercel, I would leave work and turn that part of my brain off. But ironically, because of my passion for building things, I would spend my nights and weekends writing code, reading forums, and learning about the latest tools.

When I got to Vercel, I was able to blend my passion together with my work. I loved it. The same apps I hacked on over the weekend would also help me grow in my career.

But passion without boundaries will lead you to burnout.

If you're going to go hard at work and pour everything into it, you have to also learn how to "go home". The only way you can actually turn your brain off and go home is if you've built a support system at work. The engine must keep running.

Why was I responding to tweets on the beach? I hadn't built the system for others to take ownership. I liked helping developers. I liked turning upset customers into happy ones. So I was reluctant to "give away my legos".

But you can do both. You can build a self-driving car and still take the Ferrari out for a drive sometimes. I started to spend way more time on recruiting. I hired people I'd love to work for one day. And slowly I was able to build a system that allowed me to actually disconnect from work when I needed to.

I often see advice about work/life balance that overrotates into mediocrity at work. That's not what I want. I want to go hard at work. I want to ship lots of code, respond extremely fast, create high quality content, and more. There's no substitute for putting in the hours.

But when I'm offline, I'm offline. I'm 100% focused on my wife and daughter. To be clear, I still get this wrong sometimes. It's a never ending pursuit of work/life harmony.

Takeaway: You can work really hard and set clear boundaries.

After after party NYC dinner with team Me live in 8k Trying to get the script right My favorite swag

2. Everything can be done faster

It's your job as a leader to push the pace.

My apprehension about pushing came from the fear of being disliked. I didn't want to be perceived as an asshole. But after working for leaders who pushed me, and seeing the results, I realized being pushed is much better than mediocrity and stasis.

You can push the pace without being an asshole. The ideal state is that your team both loves what they're working on and can ship fast. Teams want to feel agency and durable ownership for what they're building.

If you're okay with things moving slowly, they will. Aggressive deadlines expose hidden complexity. They force conversations about what really matters. As a leader, you can speed things up by having these conversations and helping the team narrow focus.

My goal was to build a culture that set aggressive deadlines, but also was okay with sometimes missing dates. If there's no date, it might take 3 months. But if you set a date of 2 weeks and it actually takes 1 month, great, you just shipped a first version 3x faster.

I've watched radical deadline compression many times at Vercel. It often starts with a simple question: "what would it take to ship next week instead?" Extremely talented programmers find ways to get 10x more done in the same time.

It's one of my favorite parts about roles like DX and Design Engineers. These are folks who can code, design, build, and ship. They have extreme agency and operate more like founders.

Takeaway: Your greatest advantage can be how quickly you ship, listen to feedback, and iterate on the product.

rauchg speaking the truth Delba and I doing the preshow The crowd at Ship 2023 Vercel billboard in SF DX team in 2023

3. Scale or die trying

CEOs have 1000 concurrent threads open, context-switching daily. They don't want to ping each thread to keep it alive. They need leaders who can own the thread.

Taking ownership doesn't mean doing all the work yourself. It means taking responsibility for the outcome, or if it can't be done as planned, communicating to reset expectations. To achieve this, you need to get really good at recruiting and hiring.

You must always be recruiting. If you don't scale the team, your best people get overloaded. If you get behind on hiring, you try to shield your team by doing work yourself. It's not fun.

There are only two hiring answers: hell yes or no. It means saying no to many good but not great candidates. Closing great people sometimes requires unconventional measures.

When the company is growing fast, there's always more to do than capacity allows. If you can't support another team's request because your team is too busy, you can't be upset when they find another way to get it done. You have to design an org that can say yes to the right things and no to everything else.

When someone isn't meeting the bar, you have to act fast. You want a performance and merit-based culture. At times, I felt I delivered feedback to my team early and with empathy. Other times I felt I waited too long. Those are the ones I regret.

When you delay giving critical feedback, you rob someone of the chance to improve for the sake of protecting your own feelings.

Takeaway: Scale yourself by hiring great people and building a support system.

DX team in 2025 The OG marketing squad Design GOATs Some of the best peeps Joel and Kap, legends

4. Don't swoop and poop

Let's go back to 2022 when I was promoted to VP.

We were launching a new product. I started to review the plans and became frustrated. We could not ship this. Keep in mind, I hadn't been deeply involved with this plans to build this product.

The engineering team had been working on this launch for months. Then, I came in at the last minute and started asking a bunch of questions. I poked at decisions made months ago.

I didn't have the context. I didn't understand the constraints. I just disagreed and expected people to listen to me because of my title (ouch).

You can probably guess what happened next. Everyone was mad at me! In fact, there's a fun term for this: swooping and pooping. You drop in without context, make a decision, and leave others to clean up the mess.

I made a number of mistakes here:

If this was something I cared about, I should have been involved from the start. My favorite leaders are very hands-on, contrary to the "hire good people and get out of their way" advice. If I wanted to change the direction, I needed to first establish trust with the team. I had to give them the same data and anecdotes I had. They should want to change the direction because it was objectively the right decision, not because I said so.

There's a better way that is obvious in retrospect: talk to people first. Shocking, right? You must actually listen and incorporate their feedback. Changing plans then becomes uneventful. Everyone already knows, and they all felt like they helped make the decision together.

Great leaders build alignment before making announcements. They don't use their title to override others. There will still be times when people don't agree with the direction, like team changes, but they should understand why and have built up enough trust with you that they disagree and commit.

Takeaway: Listen to your team and let the best ideas win.

Some of the Next team Behind the scenes Lee/G @ Apple Green room prep Meetup badges

5. It's okay to change your mind

I reviewed every Vercel tweet for years. I thought I had good reasons for this:

Someone needed to be the person to "stop the line" from shipping. I'd test the product, check all the links, and try to read the post from a beginner's mindset. What would someone who has never heard of Vercel think if this was the first post they read? You can't take back social posts. Sure, you could delete them, but it looked sloppy. Once the message gets out into the community, it's hard to unwind. People would tag me regardless and I'd have to go clean things up.

I became the bottleneck and there was friction getting posts out. I thought I was "doing things that don't scale" by making myself always available. But when I went on an actual vacation where I turned my phone off, I realized it wasn't working.

The process I built to ensure quality was slow and had lots of approval steps. If I'm being honest with myself, I was scared about how we would scale quality and caring. It was hard for me to admit I was wrong, because I felt principled in the reasons I created the process in the first place.

My fallacy was treating all social posts the same. As Bezos says:

"What happens in companies is that you have a one-size-fits-all decision making process, where you end up using the heavyweight process on all decisions, including the lightweight ones. Two-way door decisions should be made by individuals."

Most social posts were not actually one-way doors. If you mess up the tweet about a small feature, you could just repost it and everything will be okay. The teams working on these changes should have the autonomy to ship.

I realized I was wrong, so… I changed my mind. I gave other people autonomy and documented what good social posts looked like. Something interesting happened.

The quality didn't suffer like I feared, and others learned how to rise to the quality bar we aspired to. More people became invested in becoming better at socials because they had ownership.

Takeaway: Be willing to change your mind when presented with new information.

React Summit presentation Next.js GOATs Jam sesh with Lindsey Reactathon keynote tomo and rauchg

Following my curiosity

The only constant in my career has been following my curiosity.

I'd been a product engineer for many years prior to Vercel, teaching developers on nights and weekends. I didn't plan on joining a small startup. So when I was offered to join Vercel, I followed my curiosity and took the job. I optimized for my potential to learn.

Following curiosity also means knowing when a chapter has finished. I'm grateful and thankful to the Vercel team for the past five years. It's been one hell of a ride.

Startups are messy and imperfect, but rewarding when building something you truly believe in. And I'm a massive believer in Vercel. It's a special team of people.

I'll talk more about what's next soon. For now, a heartfelt thank you to everyone at Vercel and in the community who has been a part of this journey for the past 5 years 🖤

---

## Quick Links

### Craving
 more AI in your inbox? (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftldr.tech%2Fai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=quicklinks07112025/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/bI6-6Tz1o_SpxzbkhgFm-uJzyYp4L-_dJTQe7arQdV0=413
**TLDR Summary:** TLDR AI is your daily fix of LLMs, GenAI, and deep learning goodness. Same TLDR format. Still free. Subscribe now.
**Full Article Content:**
🧠

TLDR AI

Get smarter about AI in 5 minutes

The most important AI, ML, and data science news in a free daily email.

Sign Up

No spam. Unsubscribe at any time in one click.

---

### Craving
 more AI in your inbox? (Sponsor)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftldr.tech%2Fai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=quicklinks07112025/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/bI6-6Tz1o_SpxzbkhgFm-uJzyYp4L-_dJTQe7arQdV0=413
**TLDR Summary:** TLDR AI is your daily fix of LLMs, GenAI, and deep learning goodness. Same TLDR format. Still free. Subscribe now.
**Full Article Content:**
🧠

TLDR AI

Get smarter about AI in 5 minutes

The most important AI, ML, and data science news in a free daily email.

Sign Up

No spam. Unsubscribe at any time in one click.

---

### PEP
 779: Free-threaded Python is officially supported (1 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdocs.python.org%2F3.14%2Fwhatsnew%2F3.14.html%23whatsnew314-pep779%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/J1ZT5MHP8jW1V_oJ4mPjrV4vJroOPbxSJYvPp35xYFg=413
**TLDR Summary:** The free-threaded build of Python is now supported and no longer experimental.
**Full Article Content:**
This article explains the new features in Python 3.14, compared to 3.13.

For full details, see the changelog.

Prerelease users should be aware that this document is currently in draft form. It will be updated substantially as Python 3.14 moves towards release, so it’s worth checking back even after reading earlier versions.

The library changes include the addition of a new annotationlib module for introspecting and wrapping annotations ( PEP 749 ), a new compression.zstd module for Zstandard support ( PEP 784 ), plus syntax highlighting in the REPL, as well as the usual deprecations and removals, and improvements in user-friendliness and correctness.

The biggest changes to the implementation include template strings ( PEP 750 ), deferred evaluation of annotations ( PEP 649 ), and a new type of interpreter that uses tail calls.

Python 3.14 beta is the pre-release of the next version of the Python programming language, with a mix of changes to the language, the implementation and the standard library.

The interpreter avoids some reference count modifications internally when it’s safe to do so. This can lead to different values returned from sys.getrefcount() and Py_REFCNT() compared to previous versions of Python. See below for details.

If you encounter NameError s or pickling errors coming out of multiprocessing or concurrent.futures , see the forkserver restrictions .

On platforms other than macOS and Windows, the default start method for multiprocessing and ProcessPoolExecutor switches from fork to forkserver.

New features¶

PEP 779: Free-threaded Python is officially supported¶ The free-threaded build of Python is now supported and no longer experimental. This is the start of phase II where free-threaded Python is officially supported but still optional. We are confident that the project is on the right path, and we appreciate the continued dedication from everyone working to make free-threading ready for broader adoption across the Python community. With these recommendations and the acceptance of this PEP, we as the Python developer community should broadly advertise that free-threading is a supported Python build option now and into the future, and that it will not be removed without a proper deprecation schedule. Any decision to transition to phase III, with free-threading as the default or sole build of Python is still undecided, and dependent on many factors both within CPython itself and the community. This decision is for the future. See also PEP 779 and its acceptance.

PEP 734: Multiple interpreters in the stdlib¶ The CPython runtime supports running multiple copies of Python in the same process simultaneously and has done so for over 20 years. Each of these separate copies is called an “interpreter”. However, the feature had been available only through the C-API. That limitation is removed in the 3.14 release, with the new concurrent.interpreters module. There are at least two notable reasons why using multiple interpreters is worth considering: they support a new (to Python), human-friendly concurrency model

true multi-core parallelism For some use cases, concurrency in software enables efficiency and can simplify software, at a high level. At the same time, implementing and maintaining all but the simplest concurrency is often a struggle for the human brain. That especially applies to plain threads (for example, threading ), where all memory is shared between all threads. With multiple isolated interpreters, you can take advantage of a class of concurrency models, like CSP or the actor model, that have found success in other programming languages, like Smalltalk, Erlang, Haskell, and Go. Think of multiple interpreters like threads but with opt-in sharing. Regarding multi-core parallelism: as of the 3.12 release, interpreters are now sufficiently isolated from one another to be used in parallel. (See PEP 684.) This unlocks a variety of CPU-intensive use cases for Python that were limited by the GIL. Using multiple interpreters is similar in many ways to multiprocessing , in that they both provide isolated logical “processes” that can run in parallel, with no sharing by default. However, when using multiple interpreters, an application will use fewer system resources and will operate more efficiently (since it stays within the same process). Think of multiple interpreters as having the isolation of processes with the efficiency of threads. While the feature has been around for decades, multiple interpreters have not been used widely, due to low awareness and the lack of a stdlib module. Consequently, they currently have several notable limitations, which will improve significantly now that the feature is finally going mainstream. Current limitations: starting each interpreter has not been optimized yet

each interpreter uses more memory than necessary (we will be working next on extensive internal sharing between interpreters)

there aren’t many options yet for truly sharing objects or other data between interpreters (other than memoryview )

many extension modules on PyPI are not compatible with multiple interpreters yet (stdlib extension modules are compatible)

the approach to writing applications that use multiple isolated interpreters is mostly unfamiliar to Python users, for now The impact of these limitations will depend on future CPython improvements, how interpreters are used, and what the community solves through PyPI packages. Depending on the use case, the limitations may not have much impact, so try it out! Furthermore, future CPython releases will reduce or eliminate overhead and provide utilities that are less appropriate on PyPI. In the meantime, most of the limitations can also be addressed through extension modules, meaning PyPI packages can fill any gap for 3.14, and even back to 3.12 where interpreters were finally properly isolated and stopped sharing the GIL. Likewise, we expect to slowly see libraries on PyPI for high-level abstractions on top of interpreters. Regarding extension modules, work is in progress to update some PyPI projects, as well as tools like Cython, pybind11, nanobind, and PyO3. The steps for isolating an extension module are found at Isolating Extension Modules. Isolating a module has a lot of overlap with what is required to support free-threading, so the ongoing work in the community in that area will help accelerate support for multiple interpreters. Also added in 3.14: concurrent.futures.InterpreterPoolExecutor. See also PEP 734.

PEP 750: Template strings¶ Template string literals (t-strings) are a generalization of f-strings, using a t in place of the f prefix. Instead of evaluating to str , t-strings evaluate to a new string.templatelib.Template type: from string.templatelib import Template name = "World" template : Template = t "Hello {name} " The template can then be combined with functions that operate on the template’s structure to produce a str or a string-like result. For example, sanitizing input: evil = "<script>alert('evil')</script>" template = t "<p> {evil} </p>" assert html ( template ) == "<p><script>alert('evil')</script></p>" As another example, generating HTML attributes from data: attributes = { "src" : "shrubbery.jpg" , "alt" : "looks nice" } template = t "<img {attributes} >" assert html ( template ) == '<img src="shrubbery.jpg" alt="looks nice" />' Compared to using an f-string, the html function has access to template attributes containing the original information: static strings, interpolations, and values from the original scope. Unlike existing templating approaches, t-strings build from the well-known f-string syntax and rules. Template systems thus benefit from Python tooling as they are much closer to the Python language, syntax, scoping, and more. Writing template handlers is straightforward: from string.templatelib import Template , Interpolation def lower_upper ( template : Template ) -> str : """Render static parts lowercased and interpolations uppercased.""" parts : list [ str ] = [] for item in template : if isinstance ( item , Interpolation ): parts . append ( str ( item . value ) . upper ()) else : parts . append ( item . lower ()) return "" . join ( parts ) name = "world" assert lower_upper ( t "HELLO {name} " ) == "hello WORLD" With this in place, developers can write template systems to sanitize SQL, make safe shell operations, improve logging, tackle modern ideas in web development (HTML, CSS, and so on), and implement lightweight, custom business DSLs. (Contributed by Jim Baker, Guido van Rossum, Paul Everitt, Koudai Aono, Lysandros Nikolaou, Dave Peck, Adam Turner, Jelle Zijlstra, Bénédikt Tran, and Pablo Galindo Salgado in gh-132661.) See also PEP 750.

PEP 768: Safe external debugger interface for CPython¶ PEP 768 introduces a zero-overhead debugging interface that allows debuggers and profilers to safely attach to running Python processes. This is a significant enhancement to Python’s debugging capabilities allowing debuggers to forego unsafe alternatives. See below for how this feature is leveraged to implement the new pdb module’s remote attaching capabilities. The new interface provides safe execution points for attaching debugger code without modifying the interpreter’s normal execution path or adding runtime overhead. This enables tools to inspect and interact with Python applications in real-time without stopping or restarting them — a crucial capability for high-availability systems and production environments. For convenience, CPython implements this interface through the sys module with a sys.remote_exec() function: sys . remote_exec ( pid , script_path ) This function allows sending Python code to be executed in a target process at the next safe execution point. However, tool authors can also implement the protocol directly as described in the PEP, which details the underlying mechanisms used to safely attach to running processes. Here’s a simple example that inspects object types in a running Python process: import os import sys import tempfile # Create a temporary script with tempfile . NamedTemporaryFile ( mode = 'w' , suffix = '.py' , delete = False ) as f : script_path = f . name f . write ( f "import my_debugger; my_debugger.connect( { os . getpid () } )" ) try : # Execute in process with PID 1234 print ( "Behold! An offering:" ) sys . remote_exec ( 1234 , script_path ) finally : os . unlink ( script_path ) The debugging interface has been carefully designed with security in mind and includes several mechanisms to control access: A PYTHON_DISABLE_REMOTE_DEBUG environment variable.

A -X disable-remote-debug command-line option.

A --without-remote-debug configure flag to completely disable the feature at build time. A key implementation detail is that the interface piggybacks on the interpreter’s existing evaluation loop and safe points, ensuring zero overhead during normal execution while providing a reliable way for external processes to coordinate debugging operations. (Contributed by Pablo Galindo Salgado, Matt Wozniski, and Ivona Stojanovic in gh-131591.) See also PEP 768.

PEP 784: Adding Zstandard to the standard library¶ The new compression package contains modules compression.lzma , compression.bz2 , compression.gzip and compression.zlib which re-export the lzma , bz2 , gzip and zlib modules respectively. The new import names under compression are the canonical names for importing these compression modules going forward. However, the existing modules names have not been deprecated. Any deprecation or removal of the existing compression modules will occur no sooner than five years after the release of 3.14. The new compression.zstd module provides compression and decompression APIs for the Zstandard format via bindings to Meta’s zstd library. Zstandard is a widely adopted, highly efficient, and fast compression format. In addition to the APIs introduced in compression.zstd , support for reading and writing Zstandard compressed archives has been added to the tarfile , zipfile , and shutil modules. Here’s an example of using the new module to compress some data: from compression import zstd import math data = str ( math . pi ) . encode () * 20 compressed = zstd . compress ( data ) ratio = len ( compressed ) / len ( data ) print ( f "Achieved compression ratio of { ratio } " ) As can be seen, the API is similar to the APIs of the lzma and bz2 modules. (Contributed by Emma Harper Smith, Adam Turner, Gregory P. Smith, Tomas Roun, Victor Stinner, and Rogdham in gh-132983.) See also PEP 784.

Remote attaching to a running Python process with PDB¶ The pdb module now supports remote attaching to a running Python process using a new -p PID command-line option: python -m pdb -p 1234 This will connect to the Python process with the given PID and allow you to debug it interactively. Notice that due to how the Python interpreter works attaching to a remote process that is blocked in a system call or waiting for I/O will only work once the next bytecode instruction is executed or when the process receives a signal. This feature uses PEP 768 and the sys.remote_exec() function to attach to the remote process and send the PDB commands to it. (Contributed by Matt Wozniski and Pablo Galindo in gh-131591.) See also PEP 768.

PEP 758 – Allow except and except* expressions without parentheses¶ The except and except* expressions now allow parentheses to be omitted when there are multiple exception types and the as clause is not used. For example the following expressions are now valid: try : connect_to_server () except TimeoutError , ConnectionRefusedError : print ( "Network issue encountered." ) # The same applies to except* (for exception groups): try : connect_to_server () except * TimeoutError , ConnectionRefusedError : print ( "Network issue encountered." ) Check PEP 758 for more details. (Contributed by Pablo Galindo and Brett Cannon in gh-131831.) See also PEP 758.

PEP 649 and 749: deferred evaluation of annotations¶ The annotations on functions, classes, and modules are no longer evaluated eagerly. Instead, annotations are stored in special-purpose annotate functions and evaluated only when necessary (except if from __future__ import annotations is used). This is specified in PEP 649 and PEP 749. This change is designed to make annotations in Python more performant and more usable in most circumstances. The runtime cost for defining annotations is minimized, but it remains possible to introspect annotations at runtime. It is no longer necessary to enclose annotations in strings if they contain forward references. The new annotationlib module provides tools for inspecting deferred annotations. Annotations may be evaluated in the VALUE format (which evaluates annotations to runtime values, similar to the behavior in earlier Python versions), the FORWARDREF format (which replaces undefined names with special markers), and the STRING format (which returns annotations as strings). This example shows how these formats behave: >>> from annotationlib import get_annotations , Format >>> def func ( arg : Undefined ): ... pass >>> get_annotations ( func , format = Format . VALUE ) Traceback (most recent call last): ... NameError : name 'Undefined' is not defined >>> get_annotations ( func , format = Format . FORWARDREF ) {'arg': ForwardRef('Undefined', owner=<function func at 0x...>)} >>> get_annotations ( func , format = Format . STRING ) {'arg': 'Undefined'} Implications for annotated code¶ If you define annotations in your code (for example, for use with a static type checker), then this change probably does not affect you: you can keep writing annotations the same way you did with previous versions of Python. You will likely be able to remove quoted strings in annotations, which are frequently used for forward references. Similarly, if you use from __future__ import annotations to avoid having to write strings in annotations, you may well be able to remove that import once you support only Python 3.14 and newer. However, if you rely on third-party libraries that read annotations, those libraries may need changes to support unquoted annotations before they work as expected. Implications for readers of __annotations__ ¶ If your code reads the __annotations__ attribute on objects, you may want to make changes in order to support code that relies on deferred evaluation of annotations. For example, you may want to use annotationlib.get_annotations() with the FORWARDREF format, as the dataclasses module now does. The external typing_extensions package provides partial backports of some of the functionality of the annotationlib module, such as the Format enum and the get_annotations() function. These can be used to write cross-version code that takes advantage of the new behavior in Python 3.14. Related changes¶ The changes in Python 3.14 are designed to rework how __annotations__ works at runtime while minimizing breakage to code that contains annotations in source code and to code that reads __annotations__ . However, if you rely on undocumented details of the annotation behavior or on private functions in the standard library, there are many ways in which your code may not work in Python 3.14. To safeguard your code against future changes, use only the documented functionality of the annotationlib module. In particular, do not read annotations directly from the namespace dictionary attribute of type objects. Use annotationlib.get_annotate_from_class_namespace() during class construction and annotationlib.get_annotations() afterwards. In previous releases, it was sometimes possible to access class annotations from an instance of an annotated class. This behavior was undocumented and accidental, and will no longer work in Python 3.14. from __future__ import annotations ¶ In Python 3.7, PEP 563 introduced the from __future__ import annotations directive, which turns all annotations into strings. This directive is now considered deprecated and it is expected to be removed in a future version of Python. However, this removal will not happen until after Python 3.13, the last version of Python without deferred evaluation of annotations, reaches its end of life in 2029. In Python 3.14, the behavior of code using from __future__ import annotations is unchanged. (Contributed by Jelle Zijlstra in gh-119180; PEP 649 was written by Larry Hastings.) See also PEP 649 and PEP 749.

Improved error messages¶ The interpreter now provides helpful suggestions when it detects typos in Python keywords. When a word that closely resembles a Python keyword is encountered, the interpreter will suggest the correct keyword in the error message. This feature helps programmers quickly identify and fix common typing mistakes. For example: >>> whille True : ... pass Traceback (most recent call last): File "<stdin>" , line 1 whille True : ^^^^^^ SyntaxError : invalid syntax. Did you mean 'while'? >>> asynch def fetch_data (): ... pass Traceback (most recent call last): File "<stdin>" , line 1 asynch def fetch_data (): ^^^^^^ SyntaxError : invalid syntax. Did you mean 'async'? >>> async def foo (): ... awaid fetch_data () Traceback (most recent call last): File "<stdin>" , line 2 awaid fetch_data () ^^^^^ SyntaxError : invalid syntax. Did you mean 'await'? >>> raisee ValueError ( "Error" ) Traceback (most recent call last): File "<stdin>" , line 1 raisee ValueError ( "Error" ) ^^^^^^ SyntaxError : invalid syntax. Did you mean 'raise'? While the feature focuses on the most common cases, some variations of misspellings may still result in regular syntax errors. (Contributed by Pablo Galindo in gh-132449.)

When unpacking assignment fails due to incorrect number of variables, the error message prints the received number of values in more cases than before. (Contributed by Tushar Sadhwani in gh-122239.) >>> x , y , z = 1 , 2 , 3 , 4 Traceback (most recent call last): File "<stdin>" , line 1 , in <module> x , y , z = 1 , 2 , 3 , 4 ^^^^^^^ ValueError : too many values to unpack (expected 3, got 4)

elif statements that follow an else block now have a specific error message. (Contributed by Steele Farnsworth in gh-129902.) >>> if who == "me" : ... print ( "It's me!" ) ... else : ... print ( "It's not me!" ) ... elif who is None : ... print ( "Who is it?" ) File "<stdin>", line 5 elif who is None: ^^^^ SyntaxError: 'elif' block follows an 'else' block

If a statement ( pass , del , return , yield , raise , break , continue , assert , import , from ) is passed to the Conditional expressions after else , or one of pass , break , or continue is passed before if , then the error message highlights where the expression is required. (Contributed by Sergey Miryanov in gh-129515.) >>> x = 1 if True else pass Traceback (most recent call last): File "<string>" , line 1 x = 1 if True else pass ^^^^ SyntaxError : expected expression after 'else', but statement is given >>> x = continue if True else break Traceback (most recent call last): File "<string>" , line 1 x = continue if True else break ^^^^^^^^ SyntaxError : expected expression before 'if', but statement is given

When incorrectly closed strings are detected, the error message suggests that the string may be intended to be part of the string. (Contributed by Pablo Galindo in gh-88535.) >>> "The interesting object " The important object " is very important" Traceback (most recent call last): SyntaxError : invalid syntax. Is this intended to be part of the string?

When strings have incompatible prefixes, the error now shows which prefixes are incompatible. (Contributed by Nikita Sobolev in gh-133197.) >>> ub 'abc' File "<python-input-0>" , line 1 ub 'abc' ^^ SyntaxError : 'u' and 'b' prefixes are incompatible

Improved error messages when using as with incompatible targets in: Imports: import ... as ... From imports: from ... import ... as ... Except handlers: except ... as ... Pattern-match cases: case ... as ... (Contributed by Nikita Sobolev in gh-123539, gh-123562, and gh-123440.) >>> import ast as arr [ 0 ] File "<python-input-1>" , line 1 import ast as arr [ 0 ] ^^^^^^ SyntaxError : cannot use subscript as import target

Improved error message when trying to add an instance of an unhashable type to a dict or set . (Contributed by CF Bolz-Tereick and Victor Stinner in gh-132828.) >>> s = set () >>> s . add ({ 'pages' : 12 , 'grade' : 'A' }) Traceback (most recent call last): File "<python-input-1>" , line 1 , in <module> s . add ({ 'pages' : 12 , 'grade' : 'A' }) ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TypeError : cannot use 'dict' as a set element (unhashable type: 'dict') >>> d = {} >>> l = [ 1 , 2 , 3 ] >>> d [ l ] = 12 Traceback (most recent call last): File "<python-input-4>" , line 1 , in <module> d [ l ] = 12 ~^^^ TypeError : cannot use 'list' as a dict key (unhashable type: 'list')

PEP 741: Python configuration C API¶ Add a PyInitConfig C API to configure the Python initialization without relying on C structures and the ability to make ABI-compatible changes in the future. Complete the PEP 587 PyConfig C API by adding PyInitConfig_AddModule() which can be used to add a built-in extension module; feature previously referred to as the “inittab”. Add PyConfig_Get() and PyConfig_Set() functions to get and set the current runtime configuration. PEP 587 “Python Initialization Configuration” unified all the ways to configure the Python initialization. This PEP unifies also the configuration of the Python preinitialization and the Python initialization in a single API. Moreover, this PEP only provides a single choice to embed Python, instead of having two “Python” and “Isolated” choices (PEP 587), to simplify the API further. The lower level PEP 587 PyConfig API remains available for use cases with an intentionally higher level of coupling to CPython implementation details (such as emulating the full functionality of CPython’s CLI, including its configuration mechanisms). (Contributed by Victor Stinner in gh-107954.) See also PEP 741.

Asyncio introspection capabilities¶ Added a new command-line interface to inspect running Python processes using asynchronous tasks, available via: python -m asyncio ps PID This tool inspects the given process ID (PID) and displays information about currently running asyncio tasks. It outputs a task table: a flat listing of all tasks, their names, their coroutine stacks, and which tasks are awaiting them. python -m asyncio pstree PID This tool fetches the same information, but renders a visual async call tree, showing coroutine relationships in a hierarchical format. This command is particularly useful for debugging long-running or stuck asynchronous programs. It can help developers quickly identify where a program is blocked, what tasks are pending, and how coroutines are chained together. For example given this code: import asyncio async def play ( track ): await asyncio . sleep ( 5 ) print ( f "🎵 Finished: { track } " ) async def album ( name , tracks ): async with asyncio . TaskGroup () as tg : for track in tracks : tg . create_task ( play ( track ), name = track ) async def main (): async with asyncio . TaskGroup () as tg : tg . create_task ( album ( "Sundowning" , [ "TNDNBTG" , "Levitate" ]), name = "Sundowning" ) tg . create_task ( album ( "TMBTE" , [ "DYWTYLM" , "Aqua Regia" ]), name = "TMBTE" ) if __name__ == "__main__" : asyncio . run ( main ()) Executing the new tool on the running process will yield a table like this: python -m asyncio ps 12345 tid task id task name coroutine stack awaiter chain awaiter name awaiter id ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 1935500 0x7fc930c18050 Task-1 TaskGroup._aexit -> TaskGroup.__aexit__ -> main 0x0 1935500 0x7fc930c18230 Sundowning TaskGroup._aexit -> TaskGroup.__aexit__ -> album TaskGroup._aexit -> TaskGroup.__aexit__ -> main Task-1 0x7fc930c18050 1935500 0x7fc93173fa50 TMBTE TaskGroup._aexit -> TaskGroup.__aexit__ -> album TaskGroup._aexit -> TaskGroup.__aexit__ -> main Task-1 0x7fc930c18050 1935500 0x7fc93173fdf0 TNDNBTG sleep -> play TaskGroup._aexit -> TaskGroup.__aexit__ -> album Sundowning 0x7fc930c18230 1935500 0x7fc930d32510 Levitate sleep -> play TaskGroup._aexit -> TaskGroup.__aexit__ -> album Sundowning 0x7fc930c18230 1935500 0x7fc930d32890 DYWTYLM sleep -> play TaskGroup._aexit -> TaskGroup.__aexit__ -> album TMBTE 0x7fc93173fa50 1935500 0x7fc93161ec30 Aqua Regia sleep -> play TaskGroup._aexit -> TaskGroup.__aexit__ -> album TMBTE 0x7fc93173fa50 or a tree like this: python -m asyncio pstree 12345 └── ( T ) Task-1 └── main example.py:13 └── TaskGroup.__aexit__ Lib/asyncio/taskgroups.py:72 └── TaskGroup._aexit Lib/asyncio/taskgroups.py:121 ├── ( T ) Sundowning │ └── album example.py:8 │ └── TaskGroup.__aexit__ Lib/asyncio/taskgroups.py:72 │ └── TaskGroup._aexit Lib/asyncio/taskgroups.py:121 │ ├── ( T ) TNDNBTG │ │ └── play example.py:4 │ │ └── sleep Lib/asyncio/tasks.py:702 │ └── ( T ) Levitate │ └── play example.py:4 │ └── sleep Lib/asyncio/tasks.py:702 └── ( T ) TMBTE └── album example.py:8 └── TaskGroup.__aexit__ Lib/asyncio/taskgroups.py:72 └── TaskGroup._aexit Lib/asyncio/taskgroups.py:121 ├── ( T ) DYWTYLM │ └── play example.py:4 │ └── sleep Lib/asyncio/tasks.py:702 └── ( T ) Aqua Regia └── play example.py:4 └── sleep Lib/asyncio/tasks.py:702 If a cycle is detected in the async await graph (which could indicate a programming issue), the tool raises an error and lists the cycle paths that prevent tree construction: python -m asyncio pstree 12345 ERROR: await-graph contains cycles - cannot print a tree! cycle: Task-2 → Task-3 → Task-2 (Contributed by Pablo Galindo, Łukasz Langa, Yury Selivanov, and Marta Gomez Macias in gh-91048.)

A new type of interpreter¶ A new type of interpreter has been added to CPython. It uses tail calls between small C functions that implement individual Python opcodes, rather than one large C case statement. For certain newer compilers, this interpreter provides significantly better performance. Preliminary numbers on our machines suggest anywhere up to 30% faster Python code, and a geometric mean of 3-5% faster on pyperformance depending on platform and architecture. The baseline is Python 3.14 built with Clang 19 without this new interpreter. This interpreter currently only works with Clang 19 and newer on x86-64 and AArch64 architectures. However, we expect that a future release of GCC will support this as well. This feature is opt-in for now. We highly recommend enabling profile-guided optimization with the new interpreter as it is the only configuration we have tested and can validate its improved performance. For further information on how to build Python, see --with-tail-call-interp . Note This is not to be confused with tail call optimization of Python functions, which is currently not implemented in CPython. This new interpreter type is an internal implementation detail of the CPython interpreter. It doesn’t change the visible behavior of Python programs at all. It can improve their performance, but doesn’t change anything else. Attention This section previously reported a 9-15% geometric mean speedup. This number has since been cautiously revised down to 3-5%. While we expect performance results to be better than what we report, our estimates are more conservative due to a compiler bug found in Clang/LLVM 19, which causes the normal interpreter to be slower. We were unaware of this bug, resulting in inaccurate results. We sincerely apologize for communicating results that were only accurate for LLVM v19.1.x and v20.1.0. In the meantime, the bug has been fixed in LLVM v20.1.1 and for the upcoming v21.1, but it will remain unfixed for LLVM v19.1.x and v20.1.0. Thus any benchmarks with those versions of LLVM may produce inaccurate numbers. (Thanks to Nelson Elhage for bringing this to light.) (Contributed by Ken Jin in gh-128563, with ideas on how to implement this in CPython by Mark Shannon, Garrett Gu, Haoran Xu, and Josh Haberman.)

Free-threaded mode¶ Free-threaded mode (PEP 703), initially added in 3.13, has been significantly improved. The implementation described in PEP 703 was finished, including C API changes, and temporary workarounds in the interpreter were replaced with more permanent solutions. The specializing adaptive interpreter (PEP 659) is now enabled in free-threaded mode, which along with many other optimizations greatly improves its performance. The performance penalty on single-threaded code in free-threaded mode is now roughly 5-10%, depending on platform and C compiler used. This work was done by many contributors: Sam Gross, Matt Page, Neil Schemenauer, Thomas Wouters, Donghee Na, Kirill Podoprigora, Ken Jin, Itamar Oren, Brett Simmers, Dino Viehland, Nathan Goldbaum, Ralf Gommers, Lysandros Nikolaou, Kumar Aditya, Edgar Margffoy, and many others. Some of these contributors are employed by Meta, which has continued to provide significant engineering resources to support this project. From 3.14, when compiling extension modules for the free-threaded build of CPython on Windows, the preprocessor variable Py_GIL_DISABLED now needs to be specified by the build backend, as it will no longer be determined automatically by the C compiler. For a running interpreter, the setting that was used at compile time can be found using sysconfig.get_config_var() . A new flag has been added, context_aware_warnings . This flag defaults to true for the free-threaded build and false for the GIL-enabled build. If the flag is true then the warnings.catch_warnings context manager uses a context variable for warning filters. This makes the context manager behave predicably when used with multiple threads or asynchronous tasks. A new flag has been added, thread_inherit_context . This flag defaults to true for the free-threaded build and false for the GIL-enabled build. If the flag is true then threads created with threading.Thread start with a copy of the Context() of the caller of start() . Most significantly, this makes the warning filtering context established by catch_warnings be “inherited” by threads (or asyncio tasks) started within that context. It also affects other modules that use context variables, such as the decimal context manager.

Syntax highlighting in PyREPL¶ The default interactive shell now highlights Python syntax as you type. The feature is enabled by default unless the PYTHON_BASIC_REPL environment is set or any color-disabling environment variables are used. See Controlling color for details. The default color theme for syntax highlighting strives for good contrast and uses exclusively the 4-bit VGA standard ANSI color codes for maximum compatibility. The theme can be customized using an experimental API _colorize.set_theme() . This can be called interactively, as well as in the PYTHONSTARTUP script. (Contributed by Łukasz Langa in gh-131507.)

Binary releases for the experimental just-in-time compiler¶ The official macOS and Windows release binaries now include an experimental just-in-time (JIT) compiler. Although it is not recommended for production use, it can be tested by setting PYTHON_JIT=1 as an environment variable. Downstream source builds and redistributors can use the --enable-experimental-jit=yes-off configuration option for similar behavior. The JIT is at an early stage and still in active development. As such, the typical performance impact of enabling it can range from 10% slower to 20% faster, depending on workload. To aid in testing and evaluation, a set of introspection functions has been provided in the sys._jit namespace. sys._jit.is_available() can be used to determine if the current executable supports JIT compilation, while sys._jit.is_enabled() can be used to tell if JIT compilation has been enabled for the current process. Currently, the most significant missing functionality is that native debuggers and profilers like gdb and perf are unable to unwind through JIT frames (Python debuggers and profilers, like pdb or profile , continue to work without modification). Free-threaded builds do not support JIT compilation. Please report any bugs or major performance regressions that you encounter! See also PEP 744

---

### Varlock
 (GitHub Repo)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fdmno-dev%2Fvarlock%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/ATDI5K0AmUaIEPFFPkP7DzKOJtBGNtV4qW2y63AZJ6U=413
**TLDR Summary:** Varlock is a CLI and library that communicates with native Mac applications and enables biometric auth to securely encrypt local secrets.
**Full Article Content:**
Varlock + Env-Spec Monorepo

env-spec is a new language / DSL for attaching a schema and additional functionality to .env files using JSDoc style comments. The env-spec package contains a parser and info about the spec/language itself.

A sample .env file with a schema:

# Description # @required @sensitive MY_SECRET=my-secret

Read the RFC for more details: #17

Varlock

Varlock is our tool that uses this parser to actually load your .env files, and then applies the schema that you have defined. It is a CLI, library, and will communicate with a native Mac application that enables using biometric auth to securely encrypt your local secrets.

You can get started with varlock by installing the CLI:

# Install as standalone CLI via homebrew brew install varlock # OR install via cURL curl -sSfL https://varlock.dev/install.sh | sh -s # OR install as a dependency in a js project npx varlock init

Development

This monorepo contains the following packages:

env-spec-parser : The parser and info about the spec/language itself.

: The parser and info about the spec/language itself. varlock : The CLI that uses the parser to load your .env files, and then applies the schema to validate and load your env vars.

: The CLI that uses the parser to load your .env files, and then applies the schema to validate and load your env vars. varlock-website : The website for varlock and env-spec.

: The website for varlock and env-spec. vscode-plugin : The VSCode extension for env-spec. It provides basic syntax highlighting and IntelliSense for the env-spec language.

To get started, run:

# Install dependencies pnpm install # Build the libraries pnpm build:libs

---

### Musk:
 Grok AI Arriving in Teslas Next Week (5 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.notateslaapp.com%2Fnews%2F2902%2Fmusk-grok-ai-arriving-in-teslas-next-week%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/7AeebSI_F_Qd_hm42BeL1EBbe8eHso45lPE-aDLB4Z4=413
**TLDR Summary:** Elon Musk says that Grok 4 will arrive in Teslas by next week - it will allow drivers to talk to their vehicles more naturally and ask questions while driving.
**Full Article Content:**
We’ve been hearing about Grok, xAI’s AI assistant, coming to Teslas for almost two years now, but this is finally coming to fruition soon. XAI unveiled Grok 4 last night, but the entire stream didn’t mention Teslas. However, Musk later posted on X that Grok will arrive in Tesla vehicles “by next week.”

Between leaks and the Grok mobile app, there’s a lot we already know about Grok, but there are a few missing pieces that will be cleared when it finally arrives.

Next Week, or Next Next Week?

Musk said that Grok would arrive by next week, meaning it could arrive before then. However, based on how Musk typically states Tesla timelines, there are a few things to consider that give us a better idea of what to expect.

First, whenever Musk posts a Tesla timeline on X, he typically means when it’ll be released to employees and not a public release. Expect this to be the same thing.

Tesla releases software updates to employees first for a final round of testing before starting a gradual release to the public. Sometimes issues are found, especially with FSD updates, and the update needs some fixes before being released publicly. So expect employees to get it by next week, and not necessarily normal Tesla owners.

The second part to this is that Tesla always rolls out their updates gradually, so when it does finally arrive, it’ll only be available on a small percentage of vehicles. Tesla will gradually monitor issues and logs, continuing the rollout as long as no major issues are found.

Which Software Update?

The entire Grok UI was already included in software update 2025.20, but it’s not exposed to users. Typically, a new feature like Grok requires a vehicle update to be added; however, this version may be different, as it’s locked behind a server-side configuration.

The Tesla app was recently updated to support logging in to Grok, so it appears that all or most of the necessary pieces are already in place.

Tesla likely has the ability to enable it for all supported vehicles with a simple switch. However, we feel more confident in it being rolled out in Tesla’s next major update, which is likely to be 2025.24 or 2025.26. Rolling it out in a new update aligns with how Tesla has historically introduced features.

If they turned it on for everyone at the same time, they could be exposing everyone to potential new issues, rather than only a smaller segment of users. While Grok is now well-tested through X and the Grok app, there are several elements that are new in Teslas, likely including the ability to control various vehicle functions, such as opening the glove box or other capabilities that voice commands are currently capable of. The Grok interface in the vehicle is also entirely new and may have some bugs associated with it that will need to be addressed, especially if they impact other features.

What we can likely expect is that Tesla will make some tweaks or bug fixes to Grok with the next major update that weren’t included in update 2025.20 and they’ll begin rolling it out to employees and then customers.

Supported Vehicles

Speaking of supported vehicles, thanks to the behind-the-scenes look at Grok, we have a good idea of the vehicles that will be supported. Tesla uses the same code for most of its vehicles, but then it’s compiled for each type of hardware. However, only the needed code is compiled for each vehicle, meaning that some pieces are left out entirely. Unfortunately, Grok code is not included in Intel software builds, meaning that only AMD Ryzen-based vehicles will receive Grok, at least initially.

We’ve seen Tesla go back and add support for Intel vehicles after it initially released a feature for AMD vehicles. We saw this with the weather radar overlay and several other features in the past. However, Tesla has been developing code with web technologies lately. While this makes development easier, it just doesn’t perform as well on the slower Intel hardware, causing it to be left out. We saw this with the new Dashcam Viewer, which is entirely coded in HTML, CSS, and JS. The new viewer was available on HW3 and HW4 vehicles, but only those that included the Ryzen infotainment processor.

Grok is coming to Tesla vehicles very soon. Next week at the latest. — Elon Musk (@elonmusk) July 10, 2025

What to Expect

There’s a lot we’re expecting in Grok for Teslas. Some people will absolutely love it because it’ll completely transform their drives from a singular experience to feeling like they have a knowledgeable person sitting right next to them. Given the recent controversies surrounding Grok, some people will strongly oppose it. Hopefully, Tesla makes it easy for those users to turn off Grok.

The voice command system, which is activated through the steering wheel, is expected to be replaced with Grok. This will mean that you’ll be able to talk to your vehicle much more naturally, rather than having to remember specific syntax and commands, which should be a major improvement.

We’re personally looking forward to just being able to ask questions that pop into our heads while driving, such as What’s the date of Tesla’s next event, or How many miles away is Mars? Knowledge will be available at the touch of a finger and more accessible than ever.

Grok is also expected to support continuous conversations, meaning that you’ll be able to hold a conversation with it and go back and forth about a certain topic. While there are hints of a wake word in the code, for now, it seems like you’ll press the steering wheel button once to activate it, and then again to turn it off.

For those excited about AI and Grok, this will be one of the biggest additions to Tesla’s software in years, possibly only rivaled by the Dashcam / Sentry Mode feature and FSD Beta.

It shouldn’t be long now before we all have a chance to try it out for ourselves.

---

### My
 response to AI 2027 (21 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fvitalik.eth.limo%2Fgeneral%2F2025%2F07%2F10%2F2027.html%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/G2qJWc0SIkiOhStsiVqc1zyKh6mraItypDxkuRSC0WI=413
**TLDR Summary:** Vitalik Buterin's thoughts on AI 2027, a hypothetical scenario that predicts that humanity will have created superhuman AI by 2027 and that the entire future of civilization hinges on how that turns out.
**Full Article Content:**


---

### Co-founder
 exiting after pivot – what's a fair exit package? (Hacker News Thread)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnews.ycombinator.com%2Fitem%3Fid=44506835%26utm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/LCvka4Z8dRPMOfDg_jwzMAezaNlzvuD1Xi16VkFENII=413
**TLDR Summary:** A discussion on fair exit packages, vested equity, and cash buyouts.
**Full Article Content:**
Throwaway for obvious reasons. I’m a co-founder of a venture-backed startup currently valued at ~$20M. We raised a strong pre-seed, built a team, shipped v1, generated revenue, and recently pivoted into a related idea that I think could work—but I’m no longer the right person to lead it. My co-founder is passionate about the new direction and wants to take it forward. I want to step away cleanly and with integrity.

I have ~10% vested. I led our early fundraise, worked unpaid for months, and contributed personal capital. I’m not trying to maximize my return—but I also don’t want to walk away empty-handed after 1.5 years of building.

My question: 1. What’s a fair exit package in this situation? A formula/rule I can use?

2. Should I just keep the vested equity? Future investors may see this as dead equity.

3. Is a cash buyout common or appropriate?

How would you approach this with the board/co-founder in a way that’s constructive and protects long-term relationships?

Would love to hear from anyone who's seen this play out—on the founder, investor, or legal side.

---

### SEO
 Is Dead. Long Live GEO (8 minute read)
**URL:** https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsubstack.gauravvohra.com%2Fp%2Fsearch-is-dead-long-live-llms-winning-in-the-era-of-llms-ai-overviews-and-geo%3Futm_source=tldrnewsletter/1/01000197f9548c07-ed20a168-77c5-4d2a-b9ea-8d1cbe8deb6f-000000/-t2uejK6k37axT0HI4ylPq9JlUQpirP_JyP6aj0EnOg=413
**TLDR Summary:** This article discusses how to win in the era of LLMs, AI Overviews, and GEO.
**Full Article Content:**
Brought to you by Profound, helping brands like Ramp, MongoDB, and Indeed monitor, optimize, and grow revenue from AI search.

Track AI visibility across ChatGPT, Perplexity, and other LLMs, monitor how often AI bots are crawling your site, and create content that LLMs love.

Get 20% off Profound Lite with code GAURAV20 here.

The ground has shifted

ChatGPT hit 500 million monthly active users in May 2025.

This was the same month that Google announced AI Mode, their version of ChatGPT, directly within Google search:

Google’s AI Mode, July 2025

This is the defining moment. Google is admitting that LLMs are the search interface of the future.

Every brand is noticing the open-mouth “alligator effect” in their SEO metrics:

Impressions are up, and clicks are down. And AI is to thank — or blame, depending on how salty it makes you feel.

I see these patterns at startups I advise: ChatGPT and other LLMs are rapidly rising in “How Did You Hear About Us?”. Some of my clients have an astounding 30% of their weekly traffic from ChatGPT.

Just as important is the speed of change. For example, Vercel saw 10% of their signups come from ChatGPT in April 2025, up from 4.8% in March 2025, and 1% in October 2024.

ChatGPT and LLMs aside, most startups I work with see traditional search (i.e., Google) account for 30-50% of their signups. And as above, Google is shifting towards AI Overview and AI Mode.

So search has decisively shifted towards LLMs. And it affects every online business worldwide.

What should you do about it?

First, we’ll debunk the top two misconceptions surrounding GEO. Then we’ll dive into what to do about GEO.

This post is for anyone responsible for acquisition: founders, growth, and marketers.

Debunking common GEO misconceptions

Misconception 1: GEO is still small

Here are the facts:

Google’s AI Overviews appear at the top of over 50% of searches. This is up from 25% just 10 months ago (source). ChatGPT is already 3% of Google’s traffic. This might surpass 10% by the end of this year, and could match Google within the next 5 years (source). Google’s AI Mode is currently in beta, but if AI Overviews are any proxy, it will see rapid rollout and adoption.

GEO is already extremely important for any company whose customers find them online.

Misconception 2: GEO is the same as SEO

This is directionally true in that you need content with authority to feature in both traditional and LLM search.

But execution tactics differ.

To understand why, let’s compare traditional search and LLM search.

Difference 1: Words per query

The average traditional search is 3-5 words.

The average LLM search is extremely detailed and nuanced at 20+ words, not counting follow-ups. In traditional SEO, they would be “long tail searches”.

A traditional search strategy might manufacture content aimed at winning clicks for high-volume but low-signal traffic, like “AI notetaker”.

An LLM search strategy needs to maximize chances of being cited in a long tail search like “List the top 10 AI notetakers and give me their cost, pros, and cons”.

It must do this with rich and authoritative content with facts, benefits, advantages versus competitors, and specific use cases.

Difference 2: User results

Traditional search gives you a pile of blue links to explore.

LLMs provide one answer composed of many different sources, aiming to fully answer your question. You likely will not click through to multiple sites.

LLM traffic that does click through tends to convert extremely well. For example, Ahrefs sees LLMs represent only 0.5% of visitors but over 12% of signups. LLM search converts 12x better than traditional search.

Brands first need to win citations, then optimize websites for high-intent traffic.

Difference 3: Ranking factors

Kevin Indig, SEO expert, studied the types of content that rank well in LLMs.

He found that traditional SEO factors like backlinks, keywords, and total traffic were not significantly correlated with LLM citations.

Instead, LLMs pay attention to factors like domain authority, content comprehensiveness, and readability.

While GEO has directional overlap with SEO, the finer nuances of how to win GEO differ:

How to determine GEO priority

Hopefully you’re convinced by now that GEO is a priority.

If you’re still unsure, ask:

How fast are your customers adopting AI to search? Size traditional search. Use Google Keyword Planner, or third-party tools like Ahrefs or SEMRush. Assume half of those searches are influenced by AI Overviews. Size LLM search. Use Profound’s Conversation Explorer to quantify how often your problem space appears in LLMs. Currently available to Enterprise customers. Directly survey your customers and ask how frequently they search using LLMs like ChatGPT, Google AI Mode, and Perplexity. How do customers currently find you? Ask “How did you hear about us?” (HDYHAU) in your new user journey. This reveals when users might have heard about you in one place, for example ChatGPT, even if your attribution doesn’t track that. Read more in this Growth by Gaurav essay.

Either of these should be a trigger for you to prioritize GEO:

If >10% of your customers search with AI. If >5% of your customers already find you via AI.

Action plan for GEO

If you’ve decided GEO is a priority, here is a step-by-step playbook a single person on your team can follow.

1. Audit your foundations

Run a full technical GEO and SEO audit.

Learn the rules. For example, see Step 8 in Aleyda Solis’ guide here.

Speed up your site, nail meta tags, and page titles.

Add structured data, kill broken links, and fix duplicate content.

2. Nail your brand positioning

Mixed messaging confuses AI and users.

Clarify what you stand for. Define your core message and tone.

Make every channel reflect it: Website, social, blog, and beyond.

Tell your story the same way everywhere.

3. Identify and answer top customer questions

Answer questions early to win AI citations.

Learn from sales, support, and search forums what questions customers ask before buying.

Answer them better than anyone else.

Predict emerging questions and answer before others do.

4. Refresh existing content

Turn old pages into new growth drivers.

Audit old posts: Update statistics, fix links, and add depth.

Update language to be more precise and descriptive to help AI.

Improve structure, clarity, SEO tags, cross-links.

For an incredibly detailed guide, again refer to Aleyda Solis’ checklist here.

5. Create new authoritative content

Be the best answer on the internet.

Publish detailed landing pages, competitor comparisons, how-to guides, and answers to top questions.

Include real statistics, unique insights from subject-matter experts, and compelling case studies.

To move fast, repurpose existing media. For example, cut and transcribe existing podcasts and video clips.

6. Go beyond your website

Build an AI-friendly footprint across the internet.

Study what websites LLMs cite most often for prompts related to your business.

Profound studied the top domains per LLM from 30M citations. The top 5 sources for ChatGPT and Google AI Overviews were Wikipedia, YouTube, Reddit, Quora, and LinkedIn. Beyond this, high-trust sites like Forbes, G2, and Gartner feature heavily.

Build a web of content that features across these sites. Participate in forums, commission influencer content, publish op-eds, and more.

7. Monitor, measure, and optimize

Search is a compounding game.

Track LLM visibility, share of voice, sentiment, clicks, and HDYHAU.

Fill gaps with frequent new content and technical tune-ups.

Revisit conversion optimization and retargeting strategies to make the most of your MOFU.

Timeline to get started on GEO

Last but not least, want a concrete timeline for your GEO efforts this quarter?

Remember, it’s not whether LLMs will affect your funnel. It’s when.

Forward this to a founder, growth person, or marketer.

Until next time.

For more:

---

